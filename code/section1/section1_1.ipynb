{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mastering PyTorch\n",
    "\n",
    "## Supervised learning\n",
    "\n",
    "### Powerful PyTorch\n",
    "\n",
    "#### Accompanying notebook to Video 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libs\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup globals\n",
    "batch_size = 1\n",
    "in_features = 10\n",
    "hidden = 20\n",
    "out_features = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=20, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Sequential API example\n",
    "# Create model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(in_features, hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden, out_features)\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.1792\n",
      "[torch.FloatTensor of size (1,1)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create dummy input\n",
    "x = Variable(torch.randn(batch_size, in_features))\n",
    "# Run forward pass\n",
    "output = model(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomNet(\n",
      "  (linear1): Linear(in_features=10, out_features=20, bias=True)\n",
      "  (linear2): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (linear3): Linear(in_features=20, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Functional API example\n",
    "# Create model\n",
    "class CustomNet(nn.Module):\n",
    "    def __init__(self, in_features, hidden, out_features):\n",
    "        \"\"\"\n",
    "        Create three linear layers\n",
    "        \"\"\"\n",
    "        super(CustomNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(in_features, hidden)\n",
    "        self.linear2 = nn.Linear(hidden, hidden)\n",
    "        self.linear3 = nn.Linear(hidden, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Draw a random number from [0, 10]. \n",
    "        If it's 0, skip the second layer. Otherwise loop it!\n",
    "        \"\"\"\n",
    "        x = F.relu(self.linear1(x))\n",
    "        while random.randint(0, 10) != 0: \n",
    "        #while x.norm() > 2:\n",
    "            print('2nd layer used')\n",
    "            x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x\n",
    "\n",
    "custom_model = CustomNet(in_features, hidden, out_features)\n",
    "print(custom_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2nd layer used\n",
      "2nd layer used\n",
      "2nd layer used\n",
      "2nd layer used\n",
      "2nd layer used\n",
      "2nd layer used\n",
      "2nd layer used\n",
      "2nd layer used\n",
      "2nd layer used\n",
      "2nd layer used\n",
      "2nd layer used\n",
      "2nd layer used\n",
      "2nd layer used\n",
      "2nd layer used\n",
      "2nd layer used\n",
      "2nd layer used\n",
      "2nd layer used\n",
      "2nd layer used\n",
      "2nd layer used\n",
      "2nd layer used\n",
      "2nd layer used\n",
      "2nd layer used\n",
      "Variable containing:\n",
      "1.00000e-02 *\n",
      " -9.7912\n",
      "[torch.FloatTensor of size (1,1)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run forward pass with same dummy variable\n",
    "output = custom_model(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ConvNet example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ConvNet](images/conv_functional2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Debug example\n",
    "# Create Convnet\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, in_channels, hidden, out_features):\n",
    "        \"\"\"\n",
    "        Create ConvNet with two parallel convolutions\n",
    "        \"\"\"\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1_1 = nn.Conv2d(in_channels=in_channels,\n",
    "                                 out_channels=10,\n",
    "                                 kernel_size=3,\n",
    "                                 padding=1)\n",
    "        self.conv1_2 = nn.Conv2d(in_channels=in_channels,\n",
    "                                 out_channels=10,\n",
    "                                 kernel_size=3,\n",
    "                                 padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=20,\n",
    "                               out_channels=1,\n",
    "                               kernel_size=3,\n",
    "                               padding=1)\n",
    "        self.linear1 = nn.Linear(hidden, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Pass input through both ConvLayers and stack them afterwards\n",
    "        \"\"\"\n",
    "        x1 = F.relu(self.conv1_1(x))\n",
    "        x2 = F.relu(self.conv1_2(x))\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = self.conv2(x)\n",
    "        print('x size (after conv2): {}'.format(x.shape))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear1(x)\n",
    "        return x\n",
    "    \n",
    "conv_model = ConvNet(in_channels=3, hidden=576, out_features=out_features)\n",
    "# Create dummy input\n",
    "x_conv = Variable(torch.randn(batch_size, 3, 24, 24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x size (after conv2): torch.Size([1, 1, 24, 24])\n",
      "Variable containing:\n",
      " 0.3195\n",
      "[torch.FloatTensor of size (1,1)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run forward pass\n",
    "output = conv_model(x_conv)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Dataset / DataLoader example\n",
    "# Create a random Dataset\n",
    "class RandomDataset(Dataset):\n",
    "    def __init__(self, nb_samples, consume_time=False):\n",
    "        self.data = torch.randn(nb_samples, in_features)\n",
    "        self.target = torch.randn(nb_samples, out_features)\n",
    "        self.consume_time=consume_time\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index]\n",
    "\n",
    "        # Transform data\n",
    "        x = x + torch.FloatTensor(x.shape).normal_() * 1e-2\n",
    "        \n",
    "        if self.consume_time:\n",
    "            # Do some time consuming operation\n",
    "            for i in xrange(5000000):\n",
    "                j = i + 1\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "def train(loader):\n",
    "    for batch_idx, (data, target) in enumerate(loader):\n",
    "        # Wrap data and target into a Variable\n",
    "        data, target = Variable(data), Variable(target)\n",
    "\n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Weight update\n",
    "        optimizer.step()\n",
    "\n",
    "        print('Batch {}\\tLoss {}'.format(batch_idx, loss.data.numpy()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Dataset\n",
    "data = RandomDataset(nb_samples=30)\n",
    "# Create DataLoader\n",
    "loader = DataLoader(dataset=data,\n",
    "                    batch_size=batch_size,\n",
    "                    num_workers=0,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0\tLoss 0.0100054359064\n",
      "Batch 1\tLoss 0.325271308422\n",
      "Batch 2\tLoss 0.206538036466\n",
      "Batch 3\tLoss 0.643678188324\n",
      "Batch 4\tLoss 0.0062838695012\n",
      "Batch 5\tLoss 3.43429660797\n",
      "Batch 6\tLoss 2.78484129906\n",
      "Batch 7\tLoss 1.80068182945\n",
      "Batch 8\tLoss 1.17312073708\n",
      "Batch 9\tLoss 1.64429140091\n",
      "Batch 10\tLoss 0.14378747344\n",
      "Batch 11\tLoss 0.900345027447\n",
      "Batch 12\tLoss 2.21566462517\n",
      "Batch 13\tLoss 0.264903515577\n",
      "Batch 14\tLoss 0.652967095375\n",
      "Batch 15\tLoss 0.696649849415\n",
      "Batch 16\tLoss 0.0397122353315\n",
      "Batch 17\tLoss 1.01731193066\n",
      "Batch 18\tLoss 0.131678208709\n",
      "Batch 19\tLoss 0.00380472932011\n",
      "Batch 20\tLoss 0.0193933118135\n",
      "Batch 21\tLoss 1.26183438301\n",
      "Batch 22\tLoss 0.38179564476\n",
      "Batch 23\tLoss 1.83552241325\n",
      "Batch 24\tLoss 0.342501401901\n",
      "Batch 25\tLoss 1.9629894495\n",
      "Batch 26\tLoss 1.65481686592\n",
      "Batch 27\tLoss 1.07737565041\n",
      "Batch 28\tLoss 0.597848892212\n",
      "Batch 29\tLoss 1.65039634705\n",
      "Training finished in 0.06 seconds\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "t0 = time.time()\n",
    "train(loader)\n",
    "time_fast = time.time() - t0\n",
    "print('Training finished in {:.2f} seconds'.format(time_fast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0\tLoss 0.000563835317735\n",
      "Batch 1\tLoss 0.859951257706\n",
      "Batch 2\tLoss 0.21441693604\n",
      "Batch 3\tLoss 0.296080857515\n",
      "Batch 4\tLoss 1.13179647923\n",
      "Batch 5\tLoss 1.75049352646\n",
      "Batch 6\tLoss 0.643922448158\n",
      "Batch 7\tLoss 0.599510550499\n",
      "Batch 8\tLoss 0.901458740234\n",
      "Batch 9\tLoss 0.486395895481\n",
      "Batch 10\tLoss 1.80750954151\n",
      "Batch 11\tLoss 0.657498240471\n",
      "Batch 12\tLoss 0.00631656683981\n",
      "Batch 13\tLoss 0.657842814922\n",
      "Batch 14\tLoss 0.14444668591\n",
      "Batch 15\tLoss 1.89582431316\n",
      "Batch 16\tLoss 0.279611676931\n",
      "Batch 17\tLoss 0.223057597876\n",
      "Batch 18\tLoss 3.22094893456\n",
      "Batch 19\tLoss 2.88641214371\n",
      "Batch 20\tLoss 0.440565705299\n",
      "Batch 21\tLoss 4.95409011841\n",
      "Batch 22\tLoss 1.73405170441\n",
      "Batch 23\tLoss 3.30987095833\n",
      "Batch 24\tLoss 0.421838968992\n",
      "Batch 25\tLoss 1.42132568359\n",
      "Batch 26\tLoss 0.472670763731\n",
      "Batch 27\tLoss 5.29290962219\n",
      "Batch 28\tLoss 0.176814392209\n",
      "Batch 29\tLoss 1.1817561388\n",
      "Training finished in 12.68 seconds\n"
     ]
    }
   ],
   "source": [
    "# Create time consuming Dataset\n",
    "data_slow = RandomDataset(nb_samples=30, consume_time=True)\n",
    "loader_slow = DataLoader(dataset=data_slow,\n",
    "                         batch_size=batch_size,\n",
    "                         num_workers=0,\n",
    "                         shuffle=True)\n",
    "# Start training\n",
    "t0 = time.time()\n",
    "train(loader_slow)\n",
    "time_slow = time.time() - t0\n",
    "print('Training finished in {:.2f} seconds'.format(time_slow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0\tLoss 0.258114695549\n",
      "Batch 1\tLoss 0.364760160446\n",
      "Batch 2\tLoss 4.24717903137\n",
      "Batch 3\tLoss 0.372549623251\n",
      "Batch 4\tLoss 1.21262454987\n",
      "Batch 5\tLoss 0.654698431492\n",
      "Batch 6\tLoss 1.12767219543\n",
      "Batch 7\tLoss 1.16502165794\n",
      "Batch 8\tLoss 1.72392129898\n",
      "Batch 9\tLoss 0.812119007111\n",
      "Batch 10\tLoss 0.0791780874133\n",
      "Batch 11\tLoss 1.08515655994\n",
      "Batch 12\tLoss 4.75121450424\n",
      "Batch 13\tLoss 0.227758780122\n",
      "Batch 14\tLoss 7.81665803515e-05\n",
      "Batch 15\tLoss 0.371630400419\n",
      "Batch 16\tLoss 0.380750238895\n",
      "Batch 17\tLoss 0.0600721649826\n",
      "Batch 18\tLoss 1.81422591209\n",
      "Batch 19\tLoss 0.851997315884\n",
      "Batch 20\tLoss 2.73495793343\n",
      "Batch 21\tLoss 0.132338806987\n",
      "Batch 22\tLoss 2.66250491142\n",
      "Batch 23\tLoss 2.19154214859\n",
      "Batch 24\tLoss 0.11320348084\n",
      "Batch 25\tLoss 0.596353948116\n",
      "Batch 26\tLoss 0.495449334383\n",
      "Batch 27\tLoss 1.47845554352\n",
      "Batch 28\tLoss 0.45920842886\n",
      "Batch 29\tLoss 0.0638920143247\n",
      "Training finished in 7.44 seconds\n"
     ]
    }
   ],
   "source": [
    "loader_slow_multi_proc = DataLoader(dataset=data_slow,\n",
    "                                    batch_size=batch_size,\n",
    "                                    num_workers=4,\n",
    "                                    shuffle=True)\n",
    "# Start training\n",
    "t0 = time.time()\n",
    "train(loader_slow_multi_proc)\n",
    "time_multi_proc = time.time() - t0\n",
    "print('Training finished in {:.2f} seconds'.format(time_multi_proc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
