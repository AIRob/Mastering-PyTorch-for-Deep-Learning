{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mastering PyTorch\n",
    "\n",
    "## Supervised learning\n",
    "\n",
    "### Visualize the training in Visdom\n",
    "\n",
    "#### Accompanying notebook to Video 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Include libraries\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "from utils import get_image_name, get_number_of_cells, \\\n",
    "     split_data, download_data, SEED\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root = './'\n",
    "download_data(root=root)\n",
    "\n",
    "data_paths = os.path.join('./', 'data_paths.txt')\n",
    "if not os.path.exists(data_paths):\n",
    "  !wget http://pbialecki.de/mastering_pytorch/data_paths.txt\n",
    "\n",
    "if not os.path.isfile(data_paths):\n",
    "    print('data_paths.txt missing!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setup Globals\n",
    "use_cuda = torch.cuda.is_available()\n",
    "data_paths = os.path.join('./', 'data', 'data_paths.txt')\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    print('Using: {}'.format(torch.cuda.get_device_name(0)))\n",
    "print_steps = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def weights_init(m):\n",
    "    '''\n",
    "    Initialize the weights of each Conv2d layer using xavier_uniform\n",
    "    (\"Understanding the difficulty of training deep feedforward\n",
    "    neural networks\" - Glorot, X. & Bengio, Y. (2010))\n",
    "    '''\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.xavier_uniform(m.weight.data)\n",
    "    elif isinstance(m, nn.ConvTranspose2d):\n",
    "        nn.init.xavier_uniform(m.weight.data)\n",
    "\n",
    "def dice_loss(y_target, y_pred, smooth=0.0):\n",
    "    y_target = y_target.view(-1)\n",
    "    y_pred = y_pred.view(-1)\n",
    "    intersection = (y_target * y_pred).sum()\n",
    "    dice_coef = (2. * intersection + smooth) / (\n",
    "        y_target.sum() + y_pred.sum() + smooth)\n",
    "    return 1. - dice_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CellDataset(Dataset):\n",
    "    def __init__(self, image_paths, target_paths, size, train=False):\n",
    "        self.image_paths = image_paths\n",
    "        self.target_paths = target_paths\n",
    "        self.size = size\n",
    "        resize_size = [s+10 for s in self.size]\n",
    "        self.resize_image = transforms.Resize(\n",
    "            size=resize_size, interpolation=Image.BILINEAR)\n",
    "        self.resize_mask = transforms.Resize(\n",
    "            size=resize_size, interpolation=Image.NEAREST)\n",
    "        self.train = train\n",
    "        \n",
    "    def transform(self, image, mask):\n",
    "        # Resize\n",
    "        image = self.resize_image(image)\n",
    "        mask = self.resize_mask(mask)\n",
    "        \n",
    "        # Perform data augmentation\n",
    "        if self.train:            \n",
    "            # Random cropping\n",
    "            i, j, h, w = transforms.RandomCrop.get_params(\n",
    "                image, output_size=self.size)\n",
    "            image = TF.crop(image, i, j, h, w)\n",
    "            mask = TF.crop(mask, i, j, h, w)\n",
    "            \n",
    "            # Random horizontal flipping\n",
    "            if random.random() > 0.5:\n",
    "                image = TF.hflip(image)\n",
    "                mask = TF.hflip(mask)\n",
    "            \n",
    "            # Random vertical flipping\n",
    "            if random.random() > 0.5:\n",
    "                image = TF.vflip(image)\n",
    "                mask = TF.vflip(mask)\n",
    "        else:\n",
    "            center_crop = transforms.CenterCrop(self.size)\n",
    "            image = center_crop(image)\n",
    "            mask = center_crop(mask)\n",
    "        \n",
    "        # Transform to tensor\n",
    "        image = TF.to_tensor(image)\n",
    "        mask = TF.to_tensor(mask)\n",
    "        return image, mask\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.image_paths[index])\n",
    "        mask = Image.open(self.target_paths[index])\n",
    "        x, y = self.transform(image, mask)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_random_sample(dataset):\n",
    "    '''\n",
    "    Get a random sample from the specified dataset.\n",
    "    '''\n",
    "    data, target = dataset[int(np.random.choice(len(dataset), 1))]\n",
    "    data.unsqueeze_(0)\n",
    "    target.unsqueeze_(0)\n",
    "    if use_cuda:\n",
    "        data = data.cuda()\n",
    "        target = target.cuda()\n",
    "    data = Variable(data)\n",
    "    target = Variable(target)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BaseConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding,\n",
    "                 stride):\n",
    "        super(BaseConv, self).__init__()\n",
    "\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, padding,\n",
    "                               stride)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size,\n",
    "                               padding, stride)\n",
    "        \n",
    "        self.downsample = None\n",
    "        if in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels, out_channels, kernel_size, padding, stride)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.act(self.conv1(x))\n",
    "        out = self.conv2(out)\n",
    "        \n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.act(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DownConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding,\n",
    "                 stride):\n",
    "        super(DownConv, self).__init__()\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv_block = BaseConv(in_channels, out_channels, kernel_size,\n",
    "                                   padding, stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv_block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class UpConv(nn.Module):\n",
    "    def __init__(self, in_channels, in_channels_skip, out_channels,\n",
    "                 kernel_size, padding, stride):\n",
    "        super(UpConv, self).__init__()\n",
    "\n",
    "        self.conv_trans1 = nn.ConvTranspose2d(\n",
    "            in_channels, in_channels, kernel_size=2, padding=0, stride=2)\n",
    "        self.conv_block = BaseConv(\n",
    "            in_channels=in_channels + in_channels_skip,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=padding,\n",
    "            stride=stride)\n",
    "\n",
    "    def forward(self, x, x_skip):\n",
    "        x = self.conv_trans1(x)\n",
    "        x = torch.cat((x, x_skip), dim=1)\n",
    "        x = self.conv_block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ResUNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding,\n",
    "                 stride):\n",
    "        super(ResUNet, self).__init__()\n",
    "\n",
    "        self.init_conv = BaseConv(in_channels, out_channels, kernel_size, padding, stride)\n",
    "\n",
    "        self.down1 = DownConv(out_channels, 2 * out_channels, kernel_size,\n",
    "                              padding, stride)\n",
    "\n",
    "        self.down2 = DownConv(2 * out_channels, 4 * out_channels, kernel_size,\n",
    "                              padding, stride)\n",
    "\n",
    "        self.down3 = DownConv(4 * out_channels, 8 * out_channels, kernel_size,\n",
    "                              padding, stride)\n",
    "\n",
    "        self.up3 = UpConv(8 * out_channels, 4 * out_channels, 4 * out_channels,\n",
    "                          kernel_size, padding, stride)\n",
    "\n",
    "        self.up2 = UpConv(4 * out_channels, 2 * out_channels, 2 * out_channels,\n",
    "                          kernel_size, padding, stride)\n",
    "\n",
    "        self.up1 = UpConv(2 * out_channels, out_channels, out_channels,\n",
    "                          kernel_size, padding, stride)\n",
    "\n",
    "        self.out = nn.Conv2d(out_channels, 1, kernel_size, padding, stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x = self.init_conv(x)\n",
    "        x1 = self.down1(x)\n",
    "        x2 = self.down2(x1)\n",
    "        x3 = self.down3(x2)\n",
    "        # Decoder\n",
    "        x_up = self.up3(x3, x2)\n",
    "        x_up = self.up2(x_up, x1)\n",
    "        x_up = self.up1(x_up, x)\n",
    "        x_out = F.sigmoid(self.out(x_up))\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(epoch, visualize=False):\n",
    "    '''\n",
    "    Main training loop\n",
    "    '''\n",
    "    global win_loss\n",
    "    global win_images\n",
    "    # Set model to train mode\n",
    "    model.train()\n",
    "    # Iterate training set\n",
    "    for batch_idx, (data, mask) in enumerate(train_loader):\n",
    "        if use_cuda:\n",
    "            data = data.cuda()\n",
    "            mask = mask.cuda()\n",
    "        data = Variable(data)\n",
    "        mask = Variable(mask.squeeze())\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss_mask = criterion(output.squeeze(), mask)\n",
    "        loss_dice = dice_loss(mask, output.squeeze())\n",
    "        loss = loss_mask + loss_dice\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % print_steps == 0:\n",
    "            loss_mask_data = loss_mask.data[0]\n",
    "            loss_dice_data = loss_dice.data[0]\n",
    "            train_losses.append(loss_mask_data)\n",
    "            print(\n",
    "                'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tLoss(dice): {:.6f}'.\n",
    "                format(epoch, batch_idx * len(data),\n",
    "                       len(train_loader.dataset), 100. * batch_idx / len(\n",
    "                           train_loader), loss_mask_data, loss_dice_data))\n",
    "            \n",
    "            x_idx = (epoch - 1) * len(train_loader) + batch_idx\n",
    "            losses = [loss_mask_data, loss_dice_data]\n",
    "            win_loss = visualize_losses(losses, x_idx, win_loss)\n",
    "            \n",
    "            if visualize:\n",
    "                # Visualize some images in Visdom\n",
    "                nb_images = 4\n",
    "                images_pred = output.data[:nb_images].cpu()\n",
    "                images_target = mask.data[:nb_images].cpu().unsqueeze(1)\n",
    "                images_input = data.data[:nb_images].cpu()\n",
    "                images = torch.zeros(3 * images_pred.size(0), *images_pred.size()[1:])\n",
    "                images[::3] = images_input\n",
    "                images[1::3] = images_pred\n",
    "                images[2::3] = images_target\n",
    "                # Resize images to fit in visdom\n",
    "                images = resize_tensors(images)\n",
    "                images = make_grid(images, nrow=3, pad_value=0.5)\n",
    "                win_images = visualize_images(\n",
    "                    images.numpy(), win_images, title='Training: input - prediction - target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate():\n",
    "    '''\n",
    "    Validation loop\n",
    "    '''\n",
    "    global win_eval_images\n",
    "    # Set model to eval mode\n",
    "    model.eval()\n",
    "    # Setup val_loss\n",
    "    val_mask_loss = 0\n",
    "    val_dice_loss = 0\n",
    "    # Disable gradients (to save memory)\n",
    "    with torch.no_grad():\n",
    "        # Iterate validation set\n",
    "        for data, mask in val_loader:\n",
    "            if use_cuda:\n",
    "                data = data.cuda()\n",
    "                mask = mask.cuda()\n",
    "            data = Variable(data)\n",
    "            mask = Variable(mask.squeeze())\n",
    "            output = model(data)\n",
    "            val_mask_loss += F.binary_cross_entropy(output.squeeze(), mask).data[0]\n",
    "            val_dice_loss += dice_loss(mask, output.squeeze()).data[0]\n",
    "    # Calculate mean of validation loss\n",
    "    val_mask_loss /= len(val_loader)\n",
    "    val_dice_loss /= len(val_loader)\n",
    "    val_losses.append(val_mask_loss)\n",
    "    print('Validation\\tLoss: {:.6f}\\tLoss(dice): {:.6f}'.format(val_mask_loss, val_dice_loss))\n",
    "    \n",
    "    # Visualize some images in Visdom\n",
    "    nb_images = 4\n",
    "    images_pred = output.data[:nb_images].cpu()\n",
    "    images_target = mask.data[:nb_images].cpu().unsqueeze(1)\n",
    "    images_input = data.data[:nb_images].cpu()\n",
    "    images = torch.zeros(3 * images_pred.size(0), *images_pred.size()[1:])\n",
    "    images[::3] = images_input\n",
    "    images[1::3] = images_pred\n",
    "    images[2::3] = images_target\n",
    "    # Resize images to fit in visdom\n",
    "    images = resize_tensors(images)\n",
    "    images = make_grid(images, nrow=3, pad_value=0.5)\n",
    "    win_eval_images = visualize_images(\n",
    "        images.numpy(), win_eval_images, title='Validation: input - prediction - target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get train data folders and split to training / validation set\n",
    "with open(data_paths, 'r') as f:\n",
    "    data_paths = f.readlines()\n",
    "image_paths = [line.split(',')[0].strip() for line in data_paths]\n",
    "target_paths = [line.split(',')[1].strip() for line in data_paths]\n",
    "\n",
    "# Split data into train/validation datasets\n",
    "im_path_train, im_path_val, tar_path_train, tar_path_val = split_data(\n",
    "    image_paths, target_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = CellDataset(\n",
    "    image_paths=im_path_train,\n",
    "    target_paths=tar_path_train,\n",
    "    size=(96, 96),\n",
    "    train=True\n",
    ")\n",
    "val_dataset = CellDataset(\n",
    "    image_paths=im_path_val,\n",
    "    target_paths=tar_path_val,\n",
    "    size=(96, 96),\n",
    "    train=False\n",
    ")\n",
    "\n",
    "# Wrap in DataLoader\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=32,\n",
    "    num_workers=12,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=64,\n",
    "    num_workers=12,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creae model\n",
    "model = ResUNet(\n",
    "    in_channels=1, out_channels=32, kernel_size=3, padding=1, stride=1)\n",
    "# Initialize weights\n",
    "model.apply(weights_init)\n",
    "# Push to GPU, if available\n",
    "if use_cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create optimizer and scheduler\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "# Create criterion\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create visdom helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from visdom import Visdom\n",
    "from torchvision.utils import make_grid\n",
    "# Setup visdom\n",
    "viz = Visdom(port=6006)\n",
    "win_loss = None\n",
    "win_images = None\n",
    "win_eval_loss = None\n",
    "win_eval_images = None\n",
    "\n",
    "def visualize_losses(losses, x_idx, win):\n",
    "    if not win:\n",
    "        win = viz.line(\n",
    "            Y=np.column_stack(losses),\n",
    "            X=np.column_stack([x_idx] * len(losses)),\n",
    "            opts=dict(\n",
    "                showlegend=True,\n",
    "                xlabel='iteration',\n",
    "                ylabel='BCELoss',\n",
    "                ytype='log',\n",
    "                title='Losses',\n",
    "                legend=['Loss(mask)', 'Loss(dice)']))\n",
    "    else:\n",
    "        win = viz.line(\n",
    "            Y=np.column_stack(losses),\n",
    "            X=np.column_stack([x_idx] * len(losses)),\n",
    "            opts=dict(showlegend=True),\n",
    "            win=win,\n",
    "            update='append')\n",
    "    return win\n",
    "\n",
    "def visualize_images(images, win, title=''):\n",
    "    if not win:\n",
    "        win = viz.images(tensor=images, opts=dict(title=title))\n",
    "    else:\n",
    "        win = viz.images(tensor=images, win=win, opts=dict(title=title))\n",
    "    return win\n",
    "\n",
    "def resize_tensors(tensors, size=(128, 128)):\n",
    "    to_pil = transforms.ToPILImage()\n",
    "    res = transforms.Resize(size=size)\n",
    "    to_tensor = transforms.ToTensor()\n",
    "    images = torch.stack([to_tensor(res(to_pil(t))) for t in tensors])\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Start training\n",
    "train_losses, val_losses = [], []\n",
    "epochs = 30\n",
    "for epoch in range(1, epochs):\n",
    "    train(epoch, visualize=True)\n",
    "    validate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
