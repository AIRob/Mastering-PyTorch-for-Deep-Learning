{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mastering PyTorch\n",
    "\n",
    "## Supervised learning\n",
    "\n",
    "### Tune the training with a cusom loss\n",
    "\n",
    "#### Accompanying notebook to Video 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Include libraries\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "from utils import get_image_name, get_number_of_cells, \\\n",
    "     split_data, download_data, SEED\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root = './'\n",
    "download_data(root=root)\n",
    "\n",
    "data_paths = os.path.join('./', 'data_paths.txt')\n",
    "if not os.path.exists(data_paths):\n",
    "  !wget http://pbialecki.de/mastering_pytorch/data_paths.txt\n",
    "\n",
    "if not os.path.isfile(data_paths):\n",
    "    print('data_paths.txt missing!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: GeForce GTX 1070\n"
     ]
    }
   ],
   "source": [
    "# Setup Globals\n",
    "use_cuda = torch.cuda.is_available()\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    print('Using: {}'.format(torch.cuda.get_device_name(0)))\n",
    "print_steps = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def weights_init(m):\n",
    "    '''\n",
    "    Initialize the weights of each Conv2d layer using xavier_uniform\n",
    "    (\"Understanding the difficulty of training deep feedforward\n",
    "    neural networks\" - Glorot, X. & Bengio, Y. (2010))\n",
    "    '''\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.xavier_uniform(m.weight.data)\n",
    "        m.bias.data.zero_()\n",
    "    if isinstance(m, nn.ConvTranspose2d):\n",
    "        nn.init.xavier_uniform(m.weight.data)\n",
    "        m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CellDataset(Dataset):\n",
    "    def __init__(self, image_paths, target_paths, size, train=False):\n",
    "        self.image_paths = image_paths\n",
    "        self.target_paths = target_paths\n",
    "        self.size = size\n",
    "        resize_size = [s+10 for s in self.size]\n",
    "        self.resize_image = transforms.Resize(\n",
    "            size=resize_size, interpolation=Image.BILINEAR)\n",
    "        self.resize_mask = transforms.Resize(\n",
    "            size=resize_size, interpolation=Image.NEAREST)\n",
    "        self.train = train\n",
    "        \n",
    "    def transform(self, image, mask):\n",
    "        # Resize\n",
    "        image = self.resize_image(image)\n",
    "        mask = self.resize_mask(mask)\n",
    "        \n",
    "        # Perform data augmentation\n",
    "        if self.train:            \n",
    "            # Random cropping\n",
    "            i, j, h, w = transforms.RandomCrop.get_params(\n",
    "                image, output_size=self.size)\n",
    "            image = TF.crop(image, i, j, h, w)\n",
    "            mask = TF.crop(mask, i, j, h, w)\n",
    "            \n",
    "            # Random horizontal flipping\n",
    "            if random.random() > 0.5:\n",
    "                image = TF.hflip(image)\n",
    "                mask = TF.hflip(mask)\n",
    "            \n",
    "            # Random vertical flipping\n",
    "            if random.random() > 0.5:\n",
    "                image = TF.vflip(image)\n",
    "                mask = TF.vflip(mask)\n",
    "        else:\n",
    "            center_crop = transforms.CenterCrop(self.size)\n",
    "            image = center_crop(image)\n",
    "            mask = center_crop(mask)\n",
    "        \n",
    "        # Transform to tensor\n",
    "        image = TF.to_tensor(image)\n",
    "        mask = TF.to_tensor(mask)\n",
    "        return image, mask\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.image_paths[index])\n",
    "        mask = Image.open(self.target_paths[index])\n",
    "        x, y = self.transform(image, mask)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_random_sample(dataset):\n",
    "    '''\n",
    "    Get a random sample from the specified dataset.\n",
    "    '''\n",
    "    data, target = dataset[int(np.random.choice(len(dataset), 1))]\n",
    "    data.unsqueeze_(0)\n",
    "    target.unsqueeze_(0)\n",
    "    if use_cuda:\n",
    "        data = data.cuda()\n",
    "        target = target.cuda()\n",
    "    data = Variable(data)\n",
    "    target = Variable(target)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BaseConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding,\n",
    "                 stride):\n",
    "        super(BaseConv, self).__init__()\n",
    "\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, padding,\n",
    "                               stride)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size,\n",
    "                               padding, stride)\n",
    "        \n",
    "        self.downsample = None\n",
    "        if in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels, out_channels, kernel_size, padding, stride)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.act(self.conv1(x))\n",
    "        out = self.conv2(out)\n",
    "        \n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.act(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DownConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding,\n",
    "                 stride):\n",
    "        super(DownConv, self).__init__()\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv_block = BaseConv(in_channels, out_channels, kernel_size,\n",
    "                                   padding, stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv_block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class UpConv(nn.Module):\n",
    "    def __init__(self, in_channels, in_channels_skip, out_channels,\n",
    "                 kernel_size, padding, stride):\n",
    "        super(UpConv, self).__init__()\n",
    "\n",
    "        self.conv_trans1 = nn.ConvTranspose2d(\n",
    "            in_channels, in_channels, kernel_size=2, padding=0, stride=2)\n",
    "        self.conv_block = BaseConv(\n",
    "            in_channels=in_channels + in_channels_skip,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=padding,\n",
    "            stride=stride)\n",
    "\n",
    "    def forward(self, x, x_skip):\n",
    "        x = self.conv_trans1(x)\n",
    "        x = torch.cat((x, x_skip), dim=1)\n",
    "        x = self.conv_block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ResUNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding,\n",
    "                 stride):\n",
    "        super(ResUNet, self).__init__()\n",
    "\n",
    "        self.init_conv = BaseConv(in_channels, out_channels, kernel_size, padding, stride)\n",
    "\n",
    "        self.down1 = DownConv(out_channels, 2 * out_channels, kernel_size,\n",
    "                              padding, stride)\n",
    "\n",
    "        self.down2 = DownConv(2 * out_channels, 4 * out_channels, kernel_size,\n",
    "                              padding, stride)\n",
    "\n",
    "        self.down3 = DownConv(4 * out_channels, 8 * out_channels, kernel_size,\n",
    "                              padding, stride)\n",
    "\n",
    "        self.up3 = UpConv(8 * out_channels, 4 * out_channels, 4 * out_channels,\n",
    "                          kernel_size, padding, stride)\n",
    "\n",
    "        self.up2 = UpConv(4 * out_channels, 2 * out_channels, 2 * out_channels,\n",
    "                          kernel_size, padding, stride)\n",
    "\n",
    "        self.up1 = UpConv(2 * out_channels, out_channels, out_channels,\n",
    "                          kernel_size, padding, stride)\n",
    "\n",
    "        self.out = nn.Conv2d(out_channels, 1, kernel_size, padding, stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x = self.init_conv(x)\n",
    "        x1 = self.down1(x)\n",
    "        x2 = self.down2(x1)\n",
    "        x3 = self.down3(x2)\n",
    "        # Decoder\n",
    "        x_up = self.up3(x3, x2)\n",
    "        x_up = self.up2(x_up, x1)\n",
    "        x_up = self.up1(x_up, x)\n",
    "        x_out = F.sigmoid(self.out(x_up))\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    '''\n",
    "    Main training loop\n",
    "    '''\n",
    "    # Set model to train mode\n",
    "    model.train()\n",
    "    # Iterate training set\n",
    "    for batch_idx, (data, mask) in enumerate(train_loader):\n",
    "        if use_cuda:\n",
    "            data = data.cuda()\n",
    "            mask = mask.cuda()\n",
    "        data = Variable(data)\n",
    "        mask = Variable(mask.squeeze())\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss_mask = criterion(output.squeeze(), mask)\n",
    "        loss_dice = dice_loss(mask, output.squeeze())\n",
    "        loss = loss_mask + loss_dice\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % print_steps == 0:\n",
    "            loss_mask_data = loss_mask.data[0]\n",
    "            loss_dice_data = loss_dice.data[0]\n",
    "            train_losses.append(loss_mask_data)\n",
    "            print(\n",
    "                'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tLoss(dice): {:.6f}'.\n",
    "                format(epoch, batch_idx * len(data),\n",
    "                       len(train_loader.dataset), 100. * batch_idx / len(\n",
    "                           train_loader), loss_mask_data, loss_dice_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate():\n",
    "    '''\n",
    "    Validation loop\n",
    "    '''\n",
    "    # Set model to eval mode\n",
    "    model.eval()\n",
    "    # Setup val_loss\n",
    "    val_mask_loss = 0\n",
    "    val_dice_loss = 0\n",
    "    # Disable gradients (to save memory)\n",
    "    with torch.no_grad():\n",
    "        # Iterate validation set\n",
    "        for data, mask in val_loader:\n",
    "            if use_cuda:\n",
    "                data = data.cuda()\n",
    "                mask = mask.cuda()\n",
    "            data = Variable(data)\n",
    "            mask = Variable(mask.squeeze())\n",
    "            output = model(data)\n",
    "            val_mask_loss += F.binary_cross_entropy(output.squeeze(), mask).data[0]\n",
    "            val_dice_loss += dice_loss(mask, output.squeeze()).data[0]\n",
    "    # Calculate mean of validation loss\n",
    "    val_mask_loss /= len(val_loader)\n",
    "    val_dice_loss /= len(val_loader)\n",
    "    val_losses.append(val_mask_loss)\n",
    "    print('Validation\\tLoss: {:.6f}\\tLoss(dice): {:.6f}'.format(val_mask_loss, val_dice_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get train data folders and split to training / validation set\n",
    "with open(data_paths, 'r') as f:\n",
    "    data_paths = f.readlines()\n",
    "image_paths = [line.split(',')[0].strip() for line in data_paths]\n",
    "target_paths = [line.split(',')[1].strip() for line in data_paths]\n",
    "\n",
    "# Split data into train/validation datasets\n",
    "im_path_train, im_path_val, tar_path_train, tar_path_val = split_data(\n",
    "    image_paths, target_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = CellDataset(\n",
    "    image_paths=im_path_train,\n",
    "    target_paths=tar_path_train,\n",
    "    size=(96, 96),\n",
    "    train=True\n",
    ")\n",
    "val_dataset = CellDataset(\n",
    "    image_paths=im_path_val,\n",
    "    target_paths=tar_path_val,\n",
    "    size=(96, 96),\n",
    "    train=False\n",
    ")\n",
    "\n",
    "# Wrap in DataLoader\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=32,\n",
    "    num_workers=12,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=64,\n",
    "    num_workers=12,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creae model\n",
    "model = ResUNet(\n",
    "    in_channels=1, out_channels=32, kernel_size=3, padding=1, stride=1)\n",
    "# Initialize weights\n",
    "model.apply(weights_init)\n",
    "# Push to GPU, if available\n",
    "if use_cuda:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create optimizer and scheduler\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)\n",
    "# Create criterion\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dice coefficient\n",
    "\n",
    "Calculate the dice coefficient.\n",
    "\n",
    "Divide the \"overlap\" between the predicted and the ground truth mask by\n",
    "the total size of the two objects.\n",
    "\n",
    "\\begin{align}\n",
    "QS = \\frac{2|X \\cap Y|}{|X| + |Y|}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dice_loss(y_target, y_pred, smooth=0.0):\n",
    "    y_target = y_target.view(-1)\n",
    "    y_pred = y_pred.view(-1)\n",
    "    intersection = (y_target * y_pred).sum()\n",
    "    dice_coef = (2. * intersection + smooth) / (\n",
    "        y_target.sum() + y_pred.sum() + smooth)\n",
    "    return 1. - dice_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/8640 (0%)]\tLoss: 0.699599\tLoss(dice): 0.543329\n",
      "Train Epoch: 1 [320/8640 (4%)]\tLoss: 0.696598\tLoss(dice): 0.570614\n",
      "Train Epoch: 1 [640/8640 (7%)]\tLoss: 0.694466\tLoss(dice): 0.572270\n",
      "Train Epoch: 1 [960/8640 (11%)]\tLoss: 0.692294\tLoss(dice): 0.557642\n",
      "Train Epoch: 1 [1280/8640 (15%)]\tLoss: 0.690054\tLoss(dice): 0.569296\n",
      "Train Epoch: 1 [1600/8640 (19%)]\tLoss: 0.688195\tLoss(dice): 0.593345\n",
      "Train Epoch: 1 [1920/8640 (22%)]\tLoss: 0.685780\tLoss(dice): 0.561944\n",
      "Train Epoch: 1 [2240/8640 (26%)]\tLoss: 0.683014\tLoss(dice): 0.541047\n",
      "Train Epoch: 1 [2560/8640 (30%)]\tLoss: 0.680977\tLoss(dice): 0.548185\n",
      "Train Epoch: 1 [2880/8640 (33%)]\tLoss: 0.678386\tLoss(dice): 0.539473\n",
      "Train Epoch: 1 [3200/8640 (37%)]\tLoss: 0.677251\tLoss(dice): 0.552792\n",
      "Train Epoch: 1 [3520/8640 (41%)]\tLoss: 0.675643\tLoss(dice): 0.565948\n",
      "Train Epoch: 1 [3840/8640 (44%)]\tLoss: 0.676324\tLoss(dice): 0.610439\n",
      "Train Epoch: 1 [4160/8640 (48%)]\tLoss: 0.672479\tLoss(dice): 0.575281\n",
      "Train Epoch: 1 [4480/8640 (52%)]\tLoss: 0.668507\tLoss(dice): 0.552691\n",
      "Train Epoch: 1 [4800/8640 (56%)]\tLoss: 0.668423\tLoss(dice): 0.579040\n",
      "Train Epoch: 1 [5120/8640 (59%)]\tLoss: 0.665972\tLoss(dice): 0.563495\n",
      "Train Epoch: 1 [5440/8640 (63%)]\tLoss: 0.662882\tLoss(dice): 0.563172\n",
      "Train Epoch: 1 [5760/8640 (67%)]\tLoss: 0.660300\tLoss(dice): 0.541939\n",
      "Train Epoch: 1 [6080/8640 (70%)]\tLoss: 0.656374\tLoss(dice): 0.535128\n",
      "Train Epoch: 1 [6400/8640 (74%)]\tLoss: 0.658202\tLoss(dice): 0.585513\n",
      "Train Epoch: 1 [6720/8640 (78%)]\tLoss: 0.651576\tLoss(dice): 0.541093\n",
      "Train Epoch: 1 [7040/8640 (81%)]\tLoss: 0.651942\tLoss(dice): 0.550653\n",
      "Train Epoch: 1 [7360/8640 (85%)]\tLoss: 0.647047\tLoss(dice): 0.541412\n",
      "Train Epoch: 1 [7680/8640 (89%)]\tLoss: 0.642590\tLoss(dice): 0.531705\n",
      "Train Epoch: 1 [8000/8640 (93%)]\tLoss: 0.635512\tLoss(dice): 0.495720\n",
      "Train Epoch: 1 [8320/8640 (96%)]\tLoss: 0.635515\tLoss(dice): 0.513305\n",
      "Validation\tLoss: 0.632932\tLoss(dice): 0.523250\n",
      "Train Epoch: 2 [0/8640 (0%)]\tLoss: 0.638747\tLoss(dice): 0.568299\n",
      "Train Epoch: 2 [320/8640 (4%)]\tLoss: 0.627879\tLoss(dice): 0.509843\n",
      "Train Epoch: 2 [640/8640 (7%)]\tLoss: 0.627843\tLoss(dice): 0.530961\n",
      "Train Epoch: 2 [960/8640 (11%)]\tLoss: 0.621706\tLoss(dice): 0.519205\n",
      "Train Epoch: 2 [1280/8640 (15%)]\tLoss: 0.620414\tLoss(dice): 0.525011\n",
      "Train Epoch: 2 [1600/8640 (19%)]\tLoss: 0.615811\tLoss(dice): 0.510971\n",
      "Train Epoch: 2 [1920/8640 (22%)]\tLoss: 0.609837\tLoss(dice): 0.488899\n",
      "Train Epoch: 2 [2240/8640 (26%)]\tLoss: 0.601587\tLoss(dice): 0.475975\n",
      "Train Epoch: 2 [2560/8640 (30%)]\tLoss: 0.605687\tLoss(dice): 0.519805\n",
      "Train Epoch: 2 [2880/8640 (33%)]\tLoss: 0.592758\tLoss(dice): 0.459814\n",
      "Train Epoch: 2 [3200/8640 (37%)]\tLoss: 0.588164\tLoss(dice): 0.468726\n",
      "Train Epoch: 2 [3520/8640 (41%)]\tLoss: 0.587443\tLoss(dice): 0.474055\n",
      "Train Epoch: 2 [3840/8640 (44%)]\tLoss: 0.578237\tLoss(dice): 0.450661\n",
      "Train Epoch: 2 [4160/8640 (48%)]\tLoss: 0.578894\tLoss(dice): 0.459548\n",
      "Train Epoch: 2 [4480/8640 (52%)]\tLoss: 0.577224\tLoss(dice): 0.483476\n",
      "Train Epoch: 2 [4800/8640 (56%)]\tLoss: 0.572835\tLoss(dice): 0.473867\n",
      "Train Epoch: 2 [5120/8640 (59%)]\tLoss: 0.558507\tLoss(dice): 0.429205\n",
      "Train Epoch: 2 [5440/8640 (63%)]\tLoss: 0.546594\tLoss(dice): 0.404920\n",
      "Train Epoch: 2 [5760/8640 (67%)]\tLoss: 0.555506\tLoss(dice): 0.450277\n",
      "Train Epoch: 2 [6080/8640 (70%)]\tLoss: 0.547996\tLoss(dice): 0.417759\n",
      "Train Epoch: 2 [6400/8640 (74%)]\tLoss: 0.530679\tLoss(dice): 0.382374\n",
      "Train Epoch: 2 [6720/8640 (78%)]\tLoss: 0.529183\tLoss(dice): 0.389688\n",
      "Train Epoch: 2 [7040/8640 (81%)]\tLoss: 0.545735\tLoss(dice): 0.451604\n",
      "Train Epoch: 2 [7360/8640 (85%)]\tLoss: 0.530269\tLoss(dice): 0.412133\n",
      "Train Epoch: 2 [7680/8640 (89%)]\tLoss: 0.524865\tLoss(dice): 0.415605\n",
      "Train Epoch: 2 [8000/8640 (93%)]\tLoss: 0.522835\tLoss(dice): 0.419680\n",
      "Train Epoch: 2 [8320/8640 (96%)]\tLoss: 0.515458\tLoss(dice): 0.396944\n",
      "Validation\tLoss: 0.512549\tLoss(dice): 0.399441\n",
      "Train Epoch: 3 [0/8640 (0%)]\tLoss: 0.513570\tLoss(dice): 0.393385\n",
      "Train Epoch: 3 [320/8640 (4%)]\tLoss: 0.505951\tLoss(dice): 0.378388\n",
      "Train Epoch: 3 [640/8640 (7%)]\tLoss: 0.505181\tLoss(dice): 0.410706\n",
      "Train Epoch: 3 [960/8640 (11%)]\tLoss: 0.502050\tLoss(dice): 0.396575\n",
      "Train Epoch: 3 [1280/8640 (15%)]\tLoss: 0.498944\tLoss(dice): 0.394036\n",
      "Train Epoch: 3 [1600/8640 (19%)]\tLoss: 0.471836\tLoss(dice): 0.330628\n",
      "Train Epoch: 3 [1920/8640 (22%)]\tLoss: 0.492132\tLoss(dice): 0.408858\n",
      "Train Epoch: 3 [2240/8640 (26%)]\tLoss: 0.478281\tLoss(dice): 0.380519\n",
      "Train Epoch: 3 [2560/8640 (30%)]\tLoss: 0.466414\tLoss(dice): 0.335758\n",
      "Train Epoch: 3 [2880/8640 (33%)]\tLoss: 0.475760\tLoss(dice): 0.381604\n",
      "Train Epoch: 3 [3200/8640 (37%)]\tLoss: 0.460381\tLoss(dice): 0.352767\n",
      "Train Epoch: 3 [3520/8640 (41%)]\tLoss: 0.454871\tLoss(dice): 0.351365\n",
      "Train Epoch: 3 [3840/8640 (44%)]\tLoss: 0.446357\tLoss(dice): 0.339525\n",
      "Train Epoch: 3 [4160/8640 (48%)]\tLoss: 0.447569\tLoss(dice): 0.358413\n",
      "Train Epoch: 3 [4480/8640 (52%)]\tLoss: 0.441012\tLoss(dice): 0.330657\n",
      "Train Epoch: 3 [4800/8640 (56%)]\tLoss: 0.435847\tLoss(dice): 0.345422\n",
      "Train Epoch: 3 [5120/8640 (59%)]\tLoss: 0.435272\tLoss(dice): 0.340141\n",
      "Train Epoch: 3 [5440/8640 (63%)]\tLoss: 0.409418\tLoss(dice): 0.284449\n",
      "Train Epoch: 3 [5760/8640 (67%)]\tLoss: 0.414948\tLoss(dice): 0.298653\n",
      "Train Epoch: 3 [6080/8640 (70%)]\tLoss: 0.420083\tLoss(dice): 0.358541\n",
      "Train Epoch: 3 [6400/8640 (74%)]\tLoss: 0.416851\tLoss(dice): 0.372369\n",
      "Train Epoch: 3 [6720/8640 (78%)]\tLoss: 0.394441\tLoss(dice): 0.299286\n",
      "Train Epoch: 3 [7040/8640 (81%)]\tLoss: 0.399070\tLoss(dice): 0.333475\n",
      "Train Epoch: 3 [7360/8640 (85%)]\tLoss: 0.390243\tLoss(dice): 0.326738\n",
      "Train Epoch: 3 [7680/8640 (89%)]\tLoss: 0.388644\tLoss(dice): 0.285297\n",
      "Train Epoch: 3 [8000/8640 (93%)]\tLoss: 0.376249\tLoss(dice): 0.341823\n",
      "Train Epoch: 3 [8320/8640 (96%)]\tLoss: 0.370568\tLoss(dice): 0.295285\n",
      "Validation\tLoss: 0.362867\tLoss(dice): 0.308874\n",
      "Train Epoch: 4 [0/8640 (0%)]\tLoss: 0.370545\tLoss(dice): 0.325261\n",
      "Train Epoch: 4 [320/8640 (4%)]\tLoss: 0.360326\tLoss(dice): 0.359061\n",
      "Train Epoch: 4 [640/8640 (7%)]\tLoss: 0.352905\tLoss(dice): 0.269507\n",
      "Train Epoch: 4 [960/8640 (11%)]\tLoss: 0.342710\tLoss(dice): 0.313945\n",
      "Train Epoch: 4 [1280/8640 (15%)]\tLoss: 0.333632\tLoss(dice): 0.319667\n",
      "Train Epoch: 4 [1600/8640 (19%)]\tLoss: 0.327241\tLoss(dice): 0.265032\n",
      "Train Epoch: 4 [1920/8640 (22%)]\tLoss: 0.329038\tLoss(dice): 0.308929\n",
      "Train Epoch: 4 [2240/8640 (26%)]\tLoss: 0.310708\tLoss(dice): 0.273203\n",
      "Train Epoch: 4 [2560/8640 (30%)]\tLoss: 0.303905\tLoss(dice): 0.328546\n",
      "Train Epoch: 4 [2880/8640 (33%)]\tLoss: 0.297730\tLoss(dice): 0.259537\n",
      "Train Epoch: 4 [3200/8640 (37%)]\tLoss: 0.299755\tLoss(dice): 0.262924\n",
      "Train Epoch: 4 [3520/8640 (41%)]\tLoss: 0.285227\tLoss(dice): 0.253220\n",
      "Train Epoch: 4 [3840/8640 (44%)]\tLoss: 0.288891\tLoss(dice): 0.234775\n",
      "Train Epoch: 4 [4160/8640 (48%)]\tLoss: 0.280865\tLoss(dice): 0.260287\n",
      "Train Epoch: 4 [4480/8640 (52%)]\tLoss: 0.273415\tLoss(dice): 0.256546\n",
      "Train Epoch: 4 [4800/8640 (56%)]\tLoss: 0.264984\tLoss(dice): 0.238049\n",
      "Train Epoch: 4 [5120/8640 (59%)]\tLoss: 0.263302\tLoss(dice): 0.238030\n",
      "Train Epoch: 4 [5440/8640 (63%)]\tLoss: 0.247602\tLoss(dice): 0.223512\n",
      "Train Epoch: 4 [5760/8640 (67%)]\tLoss: 0.246959\tLoss(dice): 0.231920\n",
      "Train Epoch: 4 [6080/8640 (70%)]\tLoss: 0.241943\tLoss(dice): 0.222535\n",
      "Train Epoch: 4 [6400/8640 (74%)]\tLoss: 0.231351\tLoss(dice): 0.222802\n",
      "Train Epoch: 4 [6720/8640 (78%)]\tLoss: 0.246042\tLoss(dice): 0.195540\n",
      "Train Epoch: 4 [7040/8640 (81%)]\tLoss: 0.227633\tLoss(dice): 0.202229\n",
      "Train Epoch: 4 [7360/8640 (85%)]\tLoss: 0.214132\tLoss(dice): 0.203310\n",
      "Train Epoch: 4 [7680/8640 (89%)]\tLoss: 0.212513\tLoss(dice): 0.209818\n",
      "Train Epoch: 4 [8000/8640 (93%)]\tLoss: 0.198810\tLoss(dice): 0.232206\n",
      "Train Epoch: 4 [8320/8640 (96%)]\tLoss: 0.196593\tLoss(dice): 0.221011\n",
      "Validation\tLoss: 0.198471\tLoss(dice): 0.195633\n",
      "Train Epoch: 5 [0/8640 (0%)]\tLoss: 0.194023\tLoss(dice): 0.202087\n",
      "Train Epoch: 5 [320/8640 (4%)]\tLoss: 0.190720\tLoss(dice): 0.189905\n",
      "Train Epoch: 5 [640/8640 (7%)]\tLoss: 0.193650\tLoss(dice): 0.176795\n",
      "Train Epoch: 5 [960/8640 (11%)]\tLoss: 0.185781\tLoss(dice): 0.187273\n",
      "Train Epoch: 5 [1280/8640 (15%)]\tLoss: 0.193033\tLoss(dice): 0.159915\n",
      "Train Epoch: 5 [1600/8640 (19%)]\tLoss: 0.188745\tLoss(dice): 0.165766\n",
      "Train Epoch: 5 [1920/8640 (22%)]\tLoss: 0.184098\tLoss(dice): 0.170477\n",
      "Train Epoch: 5 [2240/8640 (26%)]\tLoss: 0.160174\tLoss(dice): 0.189052\n",
      "Train Epoch: 5 [2560/8640 (30%)]\tLoss: 0.165492\tLoss(dice): 0.184958\n",
      "Train Epoch: 5 [2880/8640 (33%)]\tLoss: 0.162197\tLoss(dice): 0.181381\n",
      "Train Epoch: 5 [3200/8640 (37%)]\tLoss: 0.164503\tLoss(dice): 0.156384\n",
      "Train Epoch: 5 [3520/8640 (41%)]\tLoss: 0.153835\tLoss(dice): 0.179111\n",
      "Train Epoch: 5 [3840/8640 (44%)]\tLoss: 0.160261\tLoss(dice): 0.149229\n",
      "Train Epoch: 5 [4160/8640 (48%)]\tLoss: 0.170192\tLoss(dice): 0.144937\n",
      "Train Epoch: 5 [4480/8640 (52%)]\tLoss: 0.171487\tLoss(dice): 0.139494\n",
      "Train Epoch: 5 [4800/8640 (56%)]\tLoss: 0.150967\tLoss(dice): 0.168548\n",
      "Train Epoch: 5 [5120/8640 (59%)]\tLoss: 0.164641\tLoss(dice): 0.135733\n",
      "Train Epoch: 5 [5440/8640 (63%)]\tLoss: 0.149778\tLoss(dice): 0.142110\n",
      "Train Epoch: 5 [5760/8640 (67%)]\tLoss: 0.142061\tLoss(dice): 0.149001\n",
      "Train Epoch: 5 [6080/8640 (70%)]\tLoss: 0.138778\tLoss(dice): 0.155491\n",
      "Train Epoch: 5 [6400/8640 (74%)]\tLoss: 0.142656\tLoss(dice): 0.143387\n",
      "Train Epoch: 5 [6720/8640 (78%)]\tLoss: 0.127211\tLoss(dice): 0.145798\n",
      "Train Epoch: 5 [7040/8640 (81%)]\tLoss: 0.131154\tLoss(dice): 0.146031\n",
      "Train Epoch: 5 [7360/8640 (85%)]\tLoss: 0.146055\tLoss(dice): 0.137422\n",
      "Train Epoch: 5 [7680/8640 (89%)]\tLoss: 0.141248\tLoss(dice): 0.129958\n",
      "Train Epoch: 5 [8000/8640 (93%)]\tLoss: 0.147934\tLoss(dice): 0.132746\n",
      "Train Epoch: 5 [8320/8640 (96%)]\tLoss: 0.138648\tLoss(dice): 0.129087\n",
      "Validation\tLoss: 0.136661\tLoss(dice): 0.129137\n",
      "Train Epoch: 6 [0/8640 (0%)]\tLoss: 0.129304\tLoss(dice): 0.128907\n",
      "Train Epoch: 6 [320/8640 (4%)]\tLoss: 0.150073\tLoss(dice): 0.128389\n",
      "Train Epoch: 6 [640/8640 (7%)]\tLoss: 0.114558\tLoss(dice): 0.135762\n",
      "Train Epoch: 6 [960/8640 (11%)]\tLoss: 0.142214\tLoss(dice): 0.121867\n",
      "Train Epoch: 6 [1280/8640 (15%)]\tLoss: 0.118490\tLoss(dice): 0.127349\n",
      "Train Epoch: 6 [1600/8640 (19%)]\tLoss: 0.138834\tLoss(dice): 0.116024\n",
      "Train Epoch: 6 [1920/8640 (22%)]\tLoss: 0.124671\tLoss(dice): 0.129796\n",
      "Train Epoch: 6 [2240/8640 (26%)]\tLoss: 0.150530\tLoss(dice): 0.125972\n",
      "Train Epoch: 6 [2560/8640 (30%)]\tLoss: 0.130772\tLoss(dice): 0.118184\n",
      "Train Epoch: 6 [2880/8640 (33%)]\tLoss: 0.136868\tLoss(dice): 0.113512\n",
      "Train Epoch: 6 [3200/8640 (37%)]\tLoss: 0.141784\tLoss(dice): 0.107464\n",
      "Train Epoch: 6 [3520/8640 (41%)]\tLoss: 0.135794\tLoss(dice): 0.122680\n",
      "Train Epoch: 6 [3840/8640 (44%)]\tLoss: 0.144340\tLoss(dice): 0.103579\n",
      "Train Epoch: 6 [4160/8640 (48%)]\tLoss: 0.139532\tLoss(dice): 0.111872\n",
      "Train Epoch: 6 [4480/8640 (52%)]\tLoss: 0.129750\tLoss(dice): 0.105170\n",
      "Train Epoch: 6 [4800/8640 (56%)]\tLoss: 0.126366\tLoss(dice): 0.117712\n",
      "Train Epoch: 6 [5120/8640 (59%)]\tLoss: 0.124442\tLoss(dice): 0.117186\n",
      "Train Epoch: 6 [5440/8640 (63%)]\tLoss: 0.137799\tLoss(dice): 0.104908\n",
      "Train Epoch: 6 [5760/8640 (67%)]\tLoss: 0.113967\tLoss(dice): 0.113893\n",
      "Train Epoch: 6 [6080/8640 (70%)]\tLoss: 0.139171\tLoss(dice): 0.109571\n",
      "Train Epoch: 6 [6400/8640 (74%)]\tLoss: 0.130465\tLoss(dice): 0.109406\n",
      "Train Epoch: 6 [6720/8640 (78%)]\tLoss: 0.112934\tLoss(dice): 0.109786\n",
      "Train Epoch: 6 [7040/8640 (81%)]\tLoss: 0.131454\tLoss(dice): 0.109874\n",
      "Train Epoch: 6 [7360/8640 (85%)]\tLoss: 0.103079\tLoss(dice): 0.113145\n",
      "Train Epoch: 6 [7680/8640 (89%)]\tLoss: 0.134692\tLoss(dice): 0.107085\n",
      "Train Epoch: 6 [8000/8640 (93%)]\tLoss: 0.128101\tLoss(dice): 0.109789\n",
      "Train Epoch: 6 [8320/8640 (96%)]\tLoss: 0.101872\tLoss(dice): 0.109057\n",
      "Validation\tLoss: 0.121697\tLoss(dice): 0.105606\n",
      "Train Epoch: 7 [0/8640 (0%)]\tLoss: 0.109403\tLoss(dice): 0.112284\n",
      "Train Epoch: 7 [320/8640 (4%)]\tLoss: 0.128639\tLoss(dice): 0.102438\n",
      "Train Epoch: 7 [640/8640 (7%)]\tLoss: 0.112082\tLoss(dice): 0.102265\n",
      "Train Epoch: 7 [960/8640 (11%)]\tLoss: 0.101583\tLoss(dice): 0.104234\n",
      "Train Epoch: 7 [1280/8640 (15%)]\tLoss: 0.103574\tLoss(dice): 0.110611\n",
      "Train Epoch: 7 [1600/8640 (19%)]\tLoss: 0.127930\tLoss(dice): 0.098467\n",
      "Train Epoch: 7 [1920/8640 (22%)]\tLoss: 0.128945\tLoss(dice): 0.103076\n",
      "Train Epoch: 7 [2240/8640 (26%)]\tLoss: 0.115223\tLoss(dice): 0.099375\n",
      "Train Epoch: 7 [2560/8640 (30%)]\tLoss: 0.125950\tLoss(dice): 0.099846\n",
      "Train Epoch: 7 [2880/8640 (33%)]\tLoss: 0.112915\tLoss(dice): 0.104555\n",
      "Train Epoch: 7 [3200/8640 (37%)]\tLoss: 0.114420\tLoss(dice): 0.101898\n",
      "Train Epoch: 7 [3520/8640 (41%)]\tLoss: 0.119709\tLoss(dice): 0.098078\n",
      "Train Epoch: 7 [3840/8640 (44%)]\tLoss: 0.121600\tLoss(dice): 0.101028\n",
      "Train Epoch: 7 [4160/8640 (48%)]\tLoss: 0.123104\tLoss(dice): 0.102325\n",
      "Train Epoch: 7 [4480/8640 (52%)]\tLoss: 0.134570\tLoss(dice): 0.095279\n",
      "Train Epoch: 7 [4800/8640 (56%)]\tLoss: 0.125031\tLoss(dice): 0.090899\n",
      "Train Epoch: 7 [5120/8640 (59%)]\tLoss: 0.111648\tLoss(dice): 0.101185\n",
      "Train Epoch: 7 [5440/8640 (63%)]\tLoss: 0.121633\tLoss(dice): 0.095361\n",
      "Train Epoch: 7 [5760/8640 (67%)]\tLoss: 0.110814\tLoss(dice): 0.097155\n",
      "Train Epoch: 7 [6080/8640 (70%)]\tLoss: 0.124093\tLoss(dice): 0.099034\n",
      "Train Epoch: 7 [6400/8640 (74%)]\tLoss: 0.125927\tLoss(dice): 0.098262\n",
      "Train Epoch: 7 [6720/8640 (78%)]\tLoss: 0.127787\tLoss(dice): 0.091409\n",
      "Train Epoch: 7 [7040/8640 (81%)]\tLoss: 0.117520\tLoss(dice): 0.100870\n",
      "Train Epoch: 7 [7360/8640 (85%)]\tLoss: 0.117808\tLoss(dice): 0.098948\n",
      "Train Epoch: 7 [7680/8640 (89%)]\tLoss: 0.116198\tLoss(dice): 0.103538\n",
      "Train Epoch: 7 [8000/8640 (93%)]\tLoss: 0.111174\tLoss(dice): 0.094996\n",
      "Train Epoch: 7 [8320/8640 (96%)]\tLoss: 0.119013\tLoss(dice): 0.096600\n",
      "Validation\tLoss: 0.116874\tLoss(dice): 0.095692\n",
      "Train Epoch: 8 [0/8640 (0%)]\tLoss: 0.124332\tLoss(dice): 0.095650\n",
      "Train Epoch: 8 [320/8640 (4%)]\tLoss: 0.126466\tLoss(dice): 0.091694\n",
      "Train Epoch: 8 [640/8640 (7%)]\tLoss: 0.124335\tLoss(dice): 0.086526\n",
      "Train Epoch: 8 [960/8640 (11%)]\tLoss: 0.098137\tLoss(dice): 0.097633\n",
      "Train Epoch: 8 [1280/8640 (15%)]\tLoss: 0.122204\tLoss(dice): 0.093600\n",
      "Train Epoch: 8 [1600/8640 (19%)]\tLoss: 0.123787\tLoss(dice): 0.094806\n",
      "Train Epoch: 8 [1920/8640 (22%)]\tLoss: 0.109220\tLoss(dice): 0.092983\n",
      "Train Epoch: 8 [2240/8640 (26%)]\tLoss: 0.109008\tLoss(dice): 0.094784\n",
      "Train Epoch: 8 [2560/8640 (30%)]\tLoss: 0.119211\tLoss(dice): 0.090433\n",
      "Train Epoch: 8 [2880/8640 (33%)]\tLoss: 0.115349\tLoss(dice): 0.096971\n",
      "Train Epoch: 8 [3200/8640 (37%)]\tLoss: 0.116661\tLoss(dice): 0.087992\n",
      "Train Epoch: 8 [3520/8640 (41%)]\tLoss: 0.108367\tLoss(dice): 0.090883\n",
      "Train Epoch: 8 [3840/8640 (44%)]\tLoss: 0.122464\tLoss(dice): 0.092616\n",
      "Train Epoch: 8 [4160/8640 (48%)]\tLoss: 0.119284\tLoss(dice): 0.092744\n",
      "Train Epoch: 8 [4480/8640 (52%)]\tLoss: 0.106095\tLoss(dice): 0.096282\n",
      "Train Epoch: 8 [4800/8640 (56%)]\tLoss: 0.110094\tLoss(dice): 0.088719\n",
      "Train Epoch: 8 [5120/8640 (59%)]\tLoss: 0.104904\tLoss(dice): 0.093806\n",
      "Train Epoch: 8 [5440/8640 (63%)]\tLoss: 0.105352\tLoss(dice): 0.099334\n",
      "Train Epoch: 8 [5760/8640 (67%)]\tLoss: 0.133474\tLoss(dice): 0.089379\n",
      "Train Epoch: 8 [6080/8640 (70%)]\tLoss: 0.122557\tLoss(dice): 0.090251\n",
      "Train Epoch: 8 [6400/8640 (74%)]\tLoss: 0.119164\tLoss(dice): 0.090973\n",
      "Train Epoch: 8 [6720/8640 (78%)]\tLoss: 0.117206\tLoss(dice): 0.091062\n",
      "Train Epoch: 8 [7040/8640 (81%)]\tLoss: 0.119379\tLoss(dice): 0.090142\n",
      "Train Epoch: 8 [7360/8640 (85%)]\tLoss: 0.116146\tLoss(dice): 0.087669\n",
      "Train Epoch: 8 [7680/8640 (89%)]\tLoss: 0.109830\tLoss(dice): 0.094387\n",
      "Train Epoch: 8 [8000/8640 (93%)]\tLoss: 0.122628\tLoss(dice): 0.087253\n",
      "Train Epoch: 8 [8320/8640 (96%)]\tLoss: 0.116867\tLoss(dice): 0.090839\n",
      "Validation\tLoss: 0.114743\tLoss(dice): 0.089862\n",
      "Train Epoch: 9 [0/8640 (0%)]\tLoss: 0.105270\tLoss(dice): 0.091382\n",
      "Train Epoch: 9 [320/8640 (4%)]\tLoss: 0.124056\tLoss(dice): 0.086097\n",
      "Train Epoch: 9 [640/8640 (7%)]\tLoss: 0.106230\tLoss(dice): 0.088005\n",
      "Train Epoch: 9 [960/8640 (11%)]\tLoss: 0.113844\tLoss(dice): 0.091783\n",
      "Train Epoch: 9 [1280/8640 (15%)]\tLoss: 0.119179\tLoss(dice): 0.085104\n",
      "Train Epoch: 9 [1600/8640 (19%)]\tLoss: 0.121779\tLoss(dice): 0.095074\n",
      "Train Epoch: 9 [1920/8640 (22%)]\tLoss: 0.113339\tLoss(dice): 0.088407\n",
      "Train Epoch: 9 [2240/8640 (26%)]\tLoss: 0.122506\tLoss(dice): 0.088388\n",
      "Train Epoch: 9 [2560/8640 (30%)]\tLoss: 0.114136\tLoss(dice): 0.092487\n",
      "Train Epoch: 9 [2880/8640 (33%)]\tLoss: 0.107042\tLoss(dice): 0.090431\n",
      "Train Epoch: 9 [3200/8640 (37%)]\tLoss: 0.108592\tLoss(dice): 0.089247\n",
      "Train Epoch: 9 [3520/8640 (41%)]\tLoss: 0.142555\tLoss(dice): 0.085636\n",
      "Train Epoch: 9 [3840/8640 (44%)]\tLoss: 0.112166\tLoss(dice): 0.086233\n",
      "Train Epoch: 9 [4160/8640 (48%)]\tLoss: 0.098809\tLoss(dice): 0.090958\n",
      "Train Epoch: 9 [4480/8640 (52%)]\tLoss: 0.102209\tLoss(dice): 0.087228\n",
      "Train Epoch: 9 [4800/8640 (56%)]\tLoss: 0.112254\tLoss(dice): 0.082971\n",
      "Train Epoch: 9 [5120/8640 (59%)]\tLoss: 0.089471\tLoss(dice): 0.086951\n",
      "Train Epoch: 9 [5440/8640 (63%)]\tLoss: 0.112055\tLoss(dice): 0.090027\n",
      "Train Epoch: 9 [5760/8640 (67%)]\tLoss: 0.109154\tLoss(dice): 0.089084\n",
      "Train Epoch: 9 [6080/8640 (70%)]\tLoss: 0.115457\tLoss(dice): 0.088839\n",
      "Train Epoch: 9 [6400/8640 (74%)]\tLoss: 0.122165\tLoss(dice): 0.088432\n",
      "Train Epoch: 9 [6720/8640 (78%)]\tLoss: 0.098509\tLoss(dice): 0.089215\n",
      "Train Epoch: 9 [7040/8640 (81%)]\tLoss: 0.096451\tLoss(dice): 0.088353\n",
      "Train Epoch: 9 [7360/8640 (85%)]\tLoss: 0.122384\tLoss(dice): 0.092906\n",
      "Train Epoch: 9 [7680/8640 (89%)]\tLoss: 0.104597\tLoss(dice): 0.087739\n",
      "Train Epoch: 9 [8000/8640 (93%)]\tLoss: 0.111844\tLoss(dice): 0.089740\n",
      "Train Epoch: 9 [8320/8640 (96%)]\tLoss: 0.124560\tLoss(dice): 0.083954\n",
      "Validation\tLoss: 0.113036\tLoss(dice): 0.086147\n",
      "Train Epoch: 10 [0/8640 (0%)]\tLoss: 0.098886\tLoss(dice): 0.081778\n",
      "Train Epoch: 10 [320/8640 (4%)]\tLoss: 0.114023\tLoss(dice): 0.083768\n",
      "Train Epoch: 10 [640/8640 (7%)]\tLoss: 0.104661\tLoss(dice): 0.084269\n",
      "Train Epoch: 10 [960/8640 (11%)]\tLoss: 0.115979\tLoss(dice): 0.089663\n",
      "Train Epoch: 10 [1280/8640 (15%)]\tLoss: 0.123631\tLoss(dice): 0.088173\n",
      "Train Epoch: 10 [1600/8640 (19%)]\tLoss: 0.112959\tLoss(dice): 0.089333\n",
      "Train Epoch: 10 [1920/8640 (22%)]\tLoss: 0.115074\tLoss(dice): 0.085080\n",
      "Train Epoch: 10 [2240/8640 (26%)]\tLoss: 0.115769\tLoss(dice): 0.084592\n",
      "Train Epoch: 10 [2560/8640 (30%)]\tLoss: 0.118483\tLoss(dice): 0.080294\n",
      "Train Epoch: 10 [2880/8640 (33%)]\tLoss: 0.116392\tLoss(dice): 0.090742\n",
      "Train Epoch: 10 [3200/8640 (37%)]\tLoss: 0.104218\tLoss(dice): 0.084739\n",
      "Train Epoch: 10 [3520/8640 (41%)]\tLoss: 0.105519\tLoss(dice): 0.085533\n",
      "Train Epoch: 10 [3840/8640 (44%)]\tLoss: 0.098955\tLoss(dice): 0.082031\n",
      "Train Epoch: 10 [4160/8640 (48%)]\tLoss: 0.112578\tLoss(dice): 0.088541\n",
      "Train Epoch: 10 [4480/8640 (52%)]\tLoss: 0.116205\tLoss(dice): 0.087241\n",
      "Train Epoch: 10 [4800/8640 (56%)]\tLoss: 0.092429\tLoss(dice): 0.084548\n",
      "Train Epoch: 10 [5120/8640 (59%)]\tLoss: 0.095542\tLoss(dice): 0.084368\n",
      "Train Epoch: 10 [5440/8640 (63%)]\tLoss: 0.121668\tLoss(dice): 0.080964\n",
      "Train Epoch: 10 [5760/8640 (67%)]\tLoss: 0.125868\tLoss(dice): 0.080514\n",
      "Train Epoch: 10 [6080/8640 (70%)]\tLoss: 0.106572\tLoss(dice): 0.082334\n",
      "Train Epoch: 10 [6400/8640 (74%)]\tLoss: 0.117313\tLoss(dice): 0.084002\n",
      "Train Epoch: 10 [6720/8640 (78%)]\tLoss: 0.121370\tLoss(dice): 0.081159\n",
      "Train Epoch: 10 [7040/8640 (81%)]\tLoss: 0.117925\tLoss(dice): 0.089186\n",
      "Train Epoch: 10 [7360/8640 (85%)]\tLoss: 0.101134\tLoss(dice): 0.085845\n",
      "Train Epoch: 10 [7680/8640 (89%)]\tLoss: 0.112881\tLoss(dice): 0.080689\n",
      "Train Epoch: 10 [8000/8640 (93%)]\tLoss: 0.121641\tLoss(dice): 0.079287\n",
      "Train Epoch: 10 [8320/8640 (96%)]\tLoss: 0.112635\tLoss(dice): 0.080684\n",
      "Validation\tLoss: 0.111408\tLoss(dice): 0.083393\n",
      "Train Epoch: 11 [0/8640 (0%)]\tLoss: 0.121428\tLoss(dice): 0.080588\n",
      "Train Epoch: 11 [320/8640 (4%)]\tLoss: 0.121532\tLoss(dice): 0.080702\n",
      "Train Epoch: 11 [640/8640 (7%)]\tLoss: 0.112089\tLoss(dice): 0.084578\n",
      "Train Epoch: 11 [960/8640 (11%)]\tLoss: 0.108189\tLoss(dice): 0.080346\n",
      "Train Epoch: 11 [1280/8640 (15%)]\tLoss: 0.101995\tLoss(dice): 0.089621\n",
      "Train Epoch: 11 [1600/8640 (19%)]\tLoss: 0.114660\tLoss(dice): 0.083118\n",
      "Train Epoch: 11 [1920/8640 (22%)]\tLoss: 0.115510\tLoss(dice): 0.082906\n",
      "Train Epoch: 11 [2240/8640 (26%)]\tLoss: 0.129295\tLoss(dice): 0.081533\n",
      "Train Epoch: 11 [2560/8640 (30%)]\tLoss: 0.070807\tLoss(dice): 0.094463\n",
      "Train Epoch: 11 [2880/8640 (33%)]\tLoss: 0.112632\tLoss(dice): 0.081044\n",
      "Train Epoch: 11 [3200/8640 (37%)]\tLoss: 0.112393\tLoss(dice): 0.085058\n",
      "Train Epoch: 11 [3520/8640 (41%)]\tLoss: 0.117756\tLoss(dice): 0.075624\n",
      "Train Epoch: 11 [3840/8640 (44%)]\tLoss: 0.107571\tLoss(dice): 0.088632\n",
      "Train Epoch: 11 [4160/8640 (48%)]\tLoss: 0.121839\tLoss(dice): 0.082216\n",
      "Train Epoch: 11 [4480/8640 (52%)]\tLoss: 0.122545\tLoss(dice): 0.083604\n",
      "Train Epoch: 11 [4800/8640 (56%)]\tLoss: 0.113907\tLoss(dice): 0.086415\n",
      "Train Epoch: 11 [5120/8640 (59%)]\tLoss: 0.101080\tLoss(dice): 0.090078\n",
      "Train Epoch: 11 [5440/8640 (63%)]\tLoss: 0.112206\tLoss(dice): 0.080505\n",
      "Train Epoch: 11 [5760/8640 (67%)]\tLoss: 0.101180\tLoss(dice): 0.086096\n",
      "Train Epoch: 11 [6080/8640 (70%)]\tLoss: 0.110949\tLoss(dice): 0.084097\n",
      "Train Epoch: 11 [6400/8640 (74%)]\tLoss: 0.120449\tLoss(dice): 0.083293\n",
      "Train Epoch: 11 [6720/8640 (78%)]\tLoss: 0.119372\tLoss(dice): 0.079940\n",
      "Train Epoch: 11 [7040/8640 (81%)]\tLoss: 0.108206\tLoss(dice): 0.083547\n",
      "Train Epoch: 11 [7360/8640 (85%)]\tLoss: 0.105998\tLoss(dice): 0.074505\n",
      "Train Epoch: 11 [7680/8640 (89%)]\tLoss: 0.113053\tLoss(dice): 0.081336\n",
      "Train Epoch: 11 [8000/8640 (93%)]\tLoss: 0.120369\tLoss(dice): 0.080031\n",
      "Train Epoch: 11 [8320/8640 (96%)]\tLoss: 0.111322\tLoss(dice): 0.081877\n",
      "Validation\tLoss: 0.109406\tLoss(dice): 0.081457\n",
      "Train Epoch: 12 [0/8640 (0%)]\tLoss: 0.097056\tLoss(dice): 0.083420\n",
      "Train Epoch: 12 [320/8640 (4%)]\tLoss: 0.117591\tLoss(dice): 0.076853\n",
      "Train Epoch: 12 [640/8640 (7%)]\tLoss: 0.087958\tLoss(dice): 0.082732\n",
      "Train Epoch: 12 [960/8640 (11%)]\tLoss: 0.117694\tLoss(dice): 0.084923\n",
      "Train Epoch: 12 [1280/8640 (15%)]\tLoss: 0.111365\tLoss(dice): 0.078015\n",
      "Train Epoch: 12 [1600/8640 (19%)]\tLoss: 0.106304\tLoss(dice): 0.081423\n",
      "Train Epoch: 12 [1920/8640 (22%)]\tLoss: 0.108509\tLoss(dice): 0.087916\n",
      "Train Epoch: 12 [2240/8640 (26%)]\tLoss: 0.088203\tLoss(dice): 0.083013\n",
      "Train Epoch: 12 [2560/8640 (30%)]\tLoss: 0.103047\tLoss(dice): 0.082584\n",
      "Train Epoch: 12 [2880/8640 (33%)]\tLoss: 0.108815\tLoss(dice): 0.083565\n",
      "Train Epoch: 12 [3200/8640 (37%)]\tLoss: 0.108720\tLoss(dice): 0.082014\n",
      "Train Epoch: 12 [3520/8640 (41%)]\tLoss: 0.105441\tLoss(dice): 0.082013\n",
      "Train Epoch: 12 [3840/8640 (44%)]\tLoss: 0.114957\tLoss(dice): 0.083956\n",
      "Train Epoch: 12 [4160/8640 (48%)]\tLoss: 0.115571\tLoss(dice): 0.075776\n",
      "Train Epoch: 12 [4480/8640 (52%)]\tLoss: 0.105207\tLoss(dice): 0.076145\n",
      "Train Epoch: 12 [4800/8640 (56%)]\tLoss: 0.111633\tLoss(dice): 0.080633\n",
      "Train Epoch: 12 [5120/8640 (59%)]\tLoss: 0.093025\tLoss(dice): 0.080958\n",
      "Train Epoch: 12 [5440/8640 (63%)]\tLoss: 0.107889\tLoss(dice): 0.081764\n",
      "Train Epoch: 12 [5760/8640 (67%)]\tLoss: 0.111888\tLoss(dice): 0.080530\n",
      "Train Epoch: 12 [6080/8640 (70%)]\tLoss: 0.103085\tLoss(dice): 0.084723\n",
      "Train Epoch: 12 [6400/8640 (74%)]\tLoss: 0.097945\tLoss(dice): 0.083057\n",
      "Train Epoch: 12 [6720/8640 (78%)]\tLoss: 0.108542\tLoss(dice): 0.082443\n",
      "Train Epoch: 12 [7040/8640 (81%)]\tLoss: 0.092934\tLoss(dice): 0.081198\n",
      "Train Epoch: 12 [7360/8640 (85%)]\tLoss: 0.093505\tLoss(dice): 0.077725\n",
      "Train Epoch: 12 [7680/8640 (89%)]\tLoss: 0.113277\tLoss(dice): 0.073843\n",
      "Train Epoch: 12 [8000/8640 (93%)]\tLoss: 0.116382\tLoss(dice): 0.080206\n",
      "Train Epoch: 12 [8320/8640 (96%)]\tLoss: 0.107885\tLoss(dice): 0.076451\n",
      "Validation\tLoss: 0.107560\tLoss(dice): 0.079428\n",
      "Train Epoch: 13 [0/8640 (0%)]\tLoss: 0.091018\tLoss(dice): 0.079747\n",
      "Train Epoch: 13 [320/8640 (4%)]\tLoss: 0.111817\tLoss(dice): 0.078394\n",
      "Train Epoch: 13 [640/8640 (7%)]\tLoss: 0.118043\tLoss(dice): 0.079644\n",
      "Train Epoch: 13 [960/8640 (11%)]\tLoss: 0.113896\tLoss(dice): 0.082113\n",
      "Train Epoch: 13 [1280/8640 (15%)]\tLoss: 0.107420\tLoss(dice): 0.076914\n",
      "Train Epoch: 13 [1600/8640 (19%)]\tLoss: 0.101522\tLoss(dice): 0.079355\n",
      "Train Epoch: 13 [1920/8640 (22%)]\tLoss: 0.102109\tLoss(dice): 0.079073\n",
      "Train Epoch: 13 [2240/8640 (26%)]\tLoss: 0.092075\tLoss(dice): 0.082592\n",
      "Train Epoch: 13 [2560/8640 (30%)]\tLoss: 0.111009\tLoss(dice): 0.080197\n",
      "Train Epoch: 13 [2880/8640 (33%)]\tLoss: 0.113278\tLoss(dice): 0.077334\n",
      "Train Epoch: 13 [3200/8640 (37%)]\tLoss: 0.091926\tLoss(dice): 0.083968\n",
      "Train Epoch: 13 [3520/8640 (41%)]\tLoss: 0.095166\tLoss(dice): 0.075086\n",
      "Train Epoch: 13 [3840/8640 (44%)]\tLoss: 0.108171\tLoss(dice): 0.076747\n",
      "Train Epoch: 13 [4160/8640 (48%)]\tLoss: 0.105174\tLoss(dice): 0.077351\n",
      "Train Epoch: 13 [4480/8640 (52%)]\tLoss: 0.099813\tLoss(dice): 0.078703\n",
      "Train Epoch: 13 [4800/8640 (56%)]\tLoss: 0.111203\tLoss(dice): 0.078963\n",
      "Train Epoch: 13 [5120/8640 (59%)]\tLoss: 0.104468\tLoss(dice): 0.077692\n",
      "Train Epoch: 13 [5440/8640 (63%)]\tLoss: 0.101070\tLoss(dice): 0.079535\n",
      "Train Epoch: 13 [5760/8640 (67%)]\tLoss: 0.103307\tLoss(dice): 0.071689\n",
      "Train Epoch: 13 [6080/8640 (70%)]\tLoss: 0.106178\tLoss(dice): 0.075331\n",
      "Train Epoch: 13 [6400/8640 (74%)]\tLoss: 0.106355\tLoss(dice): 0.077871\n",
      "Train Epoch: 13 [6720/8640 (78%)]\tLoss: 0.122774\tLoss(dice): 0.082030\n",
      "Train Epoch: 13 [7040/8640 (81%)]\tLoss: 0.105855\tLoss(dice): 0.074297\n",
      "Train Epoch: 13 [7360/8640 (85%)]\tLoss: 0.094428\tLoss(dice): 0.080321\n",
      "Train Epoch: 13 [7680/8640 (89%)]\tLoss: 0.113227\tLoss(dice): 0.073187\n",
      "Train Epoch: 13 [8000/8640 (93%)]\tLoss: 0.136778\tLoss(dice): 0.069539\n",
      "Train Epoch: 13 [8320/8640 (96%)]\tLoss: 0.099008\tLoss(dice): 0.078741\n",
      "Validation\tLoss: 0.105419\tLoss(dice): 0.077765\n",
      "Train Epoch: 14 [0/8640 (0%)]\tLoss: 0.107829\tLoss(dice): 0.077716\n",
      "Train Epoch: 14 [320/8640 (4%)]\tLoss: 0.093995\tLoss(dice): 0.076782\n",
      "Train Epoch: 14 [640/8640 (7%)]\tLoss: 0.105973\tLoss(dice): 0.076767\n",
      "Train Epoch: 14 [960/8640 (11%)]\tLoss: 0.102414\tLoss(dice): 0.078610\n",
      "Train Epoch: 14 [1280/8640 (15%)]\tLoss: 0.112191\tLoss(dice): 0.074033\n",
      "Train Epoch: 14 [1600/8640 (19%)]\tLoss: 0.123449\tLoss(dice): 0.078461\n",
      "Train Epoch: 14 [1920/8640 (22%)]\tLoss: 0.109969\tLoss(dice): 0.074833\n",
      "Train Epoch: 14 [2240/8640 (26%)]\tLoss: 0.099108\tLoss(dice): 0.075588\n",
      "Train Epoch: 14 [2560/8640 (30%)]\tLoss: 0.096982\tLoss(dice): 0.081438\n",
      "Train Epoch: 14 [2880/8640 (33%)]\tLoss: 0.112452\tLoss(dice): 0.079406\n",
      "Train Epoch: 14 [3200/8640 (37%)]\tLoss: 0.102312\tLoss(dice): 0.071068\n",
      "Train Epoch: 14 [3520/8640 (41%)]\tLoss: 0.102287\tLoss(dice): 0.074118\n",
      "Train Epoch: 14 [3840/8640 (44%)]\tLoss: 0.102063\tLoss(dice): 0.077603\n",
      "Train Epoch: 14 [4160/8640 (48%)]\tLoss: 0.110076\tLoss(dice): 0.075154\n",
      "Train Epoch: 14 [4480/8640 (52%)]\tLoss: 0.099886\tLoss(dice): 0.076461\n",
      "Train Epoch: 14 [4800/8640 (56%)]\tLoss: 0.102486\tLoss(dice): 0.078161\n",
      "Train Epoch: 14 [5120/8640 (59%)]\tLoss: 0.105475\tLoss(dice): 0.071835\n",
      "Train Epoch: 14 [5440/8640 (63%)]\tLoss: 0.094201\tLoss(dice): 0.078577\n",
      "Train Epoch: 14 [5760/8640 (67%)]\tLoss: 0.096963\tLoss(dice): 0.075086\n",
      "Train Epoch: 14 [6080/8640 (70%)]\tLoss: 0.111974\tLoss(dice): 0.075441\n",
      "Train Epoch: 14 [6400/8640 (74%)]\tLoss: 0.091937\tLoss(dice): 0.072997\n",
      "Train Epoch: 14 [6720/8640 (78%)]\tLoss: 0.095786\tLoss(dice): 0.073875\n",
      "Train Epoch: 14 [7040/8640 (81%)]\tLoss: 0.122426\tLoss(dice): 0.071792\n",
      "Train Epoch: 14 [7360/8640 (85%)]\tLoss: 0.109028\tLoss(dice): 0.075335\n",
      "Train Epoch: 14 [7680/8640 (89%)]\tLoss: 0.101349\tLoss(dice): 0.075666\n",
      "Train Epoch: 14 [8000/8640 (93%)]\tLoss: 0.108164\tLoss(dice): 0.075011\n",
      "Train Epoch: 14 [8320/8640 (96%)]\tLoss: 0.068361\tLoss(dice): 0.081085\n",
      "Validation\tLoss: 0.103348\tLoss(dice): 0.076204\n",
      "Train Epoch: 15 [0/8640 (0%)]\tLoss: 0.093347\tLoss(dice): 0.075951\n",
      "Train Epoch: 15 [320/8640 (4%)]\tLoss: 0.097715\tLoss(dice): 0.078209\n",
      "Train Epoch: 15 [640/8640 (7%)]\tLoss: 0.113758\tLoss(dice): 0.072322\n",
      "Train Epoch: 15 [960/8640 (11%)]\tLoss: 0.100047\tLoss(dice): 0.078798\n",
      "Train Epoch: 15 [1280/8640 (15%)]\tLoss: 0.112655\tLoss(dice): 0.080189\n",
      "Train Epoch: 15 [1600/8640 (19%)]\tLoss: 0.097282\tLoss(dice): 0.072996\n",
      "Train Epoch: 15 [1920/8640 (22%)]\tLoss: 0.105040\tLoss(dice): 0.079338\n",
      "Train Epoch: 15 [2240/8640 (26%)]\tLoss: 0.086382\tLoss(dice): 0.074858\n",
      "Train Epoch: 15 [2560/8640 (30%)]\tLoss: 0.088520\tLoss(dice): 0.071617\n",
      "Train Epoch: 15 [2880/8640 (33%)]\tLoss: 0.124390\tLoss(dice): 0.073164\n",
      "Train Epoch: 15 [3200/8640 (37%)]\tLoss: 0.108018\tLoss(dice): 0.071351\n",
      "Train Epoch: 15 [3520/8640 (41%)]\tLoss: 0.082942\tLoss(dice): 0.082541\n",
      "Train Epoch: 15 [3840/8640 (44%)]\tLoss: 0.086341\tLoss(dice): 0.071202\n",
      "Train Epoch: 15 [4160/8640 (48%)]\tLoss: 0.105110\tLoss(dice): 0.073757\n",
      "Train Epoch: 15 [4480/8640 (52%)]\tLoss: 0.111279\tLoss(dice): 0.078370\n",
      "Train Epoch: 15 [4800/8640 (56%)]\tLoss: 0.092843\tLoss(dice): 0.077573\n",
      "Train Epoch: 15 [5120/8640 (59%)]\tLoss: 0.110326\tLoss(dice): 0.075019\n",
      "Train Epoch: 15 [5440/8640 (63%)]\tLoss: 0.109525\tLoss(dice): 0.072810\n",
      "Train Epoch: 15 [5760/8640 (67%)]\tLoss: 0.095041\tLoss(dice): 0.080652\n",
      "Train Epoch: 15 [6080/8640 (70%)]\tLoss: 0.091258\tLoss(dice): 0.076293\n",
      "Train Epoch: 15 [6400/8640 (74%)]\tLoss: 0.090300\tLoss(dice): 0.074189\n",
      "Train Epoch: 15 [6720/8640 (78%)]\tLoss: 0.095829\tLoss(dice): 0.072412\n",
      "Train Epoch: 15 [7040/8640 (81%)]\tLoss: 0.104864\tLoss(dice): 0.072348\n",
      "Train Epoch: 15 [7360/8640 (85%)]\tLoss: 0.097367\tLoss(dice): 0.078819\n",
      "Train Epoch: 15 [7680/8640 (89%)]\tLoss: 0.096327\tLoss(dice): 0.074183\n",
      "Train Epoch: 15 [8000/8640 (93%)]\tLoss: 0.117092\tLoss(dice): 0.074889\n",
      "Train Epoch: 15 [8320/8640 (96%)]\tLoss: 0.085574\tLoss(dice): 0.073707\n",
      "Validation\tLoss: 0.101391\tLoss(dice): 0.074803\n",
      "Train Epoch: 16 [0/8640 (0%)]\tLoss: 0.089956\tLoss(dice): 0.078040\n",
      "Train Epoch: 16 [320/8640 (4%)]\tLoss: 0.099575\tLoss(dice): 0.076746\n",
      "Train Epoch: 16 [640/8640 (7%)]\tLoss: 0.116610\tLoss(dice): 0.075148\n",
      "Train Epoch: 16 [960/8640 (11%)]\tLoss: 0.095022\tLoss(dice): 0.073957\n",
      "Train Epoch: 16 [1280/8640 (15%)]\tLoss: 0.095362\tLoss(dice): 0.074930\n",
      "Train Epoch: 16 [1600/8640 (19%)]\tLoss: 0.101517\tLoss(dice): 0.075096\n",
      "Train Epoch: 16 [1920/8640 (22%)]\tLoss: 0.107097\tLoss(dice): 0.076608\n",
      "Train Epoch: 16 [2240/8640 (26%)]\tLoss: 0.080423\tLoss(dice): 0.073712\n",
      "Train Epoch: 16 [2560/8640 (30%)]\tLoss: 0.102692\tLoss(dice): 0.071515\n",
      "Train Epoch: 16 [2880/8640 (33%)]\tLoss: 0.101466\tLoss(dice): 0.071665\n",
      "Train Epoch: 16 [3200/8640 (37%)]\tLoss: 0.089159\tLoss(dice): 0.077966\n",
      "Train Epoch: 16 [3520/8640 (41%)]\tLoss: 0.094679\tLoss(dice): 0.075616\n",
      "Train Epoch: 16 [3840/8640 (44%)]\tLoss: 0.100146\tLoss(dice): 0.076407\n",
      "Train Epoch: 16 [4160/8640 (48%)]\tLoss: 0.119383\tLoss(dice): 0.072212\n",
      "Train Epoch: 16 [4480/8640 (52%)]\tLoss: 0.092929\tLoss(dice): 0.077831\n",
      "Train Epoch: 16 [4800/8640 (56%)]\tLoss: 0.087504\tLoss(dice): 0.073905\n",
      "Train Epoch: 16 [5120/8640 (59%)]\tLoss: 0.093450\tLoss(dice): 0.069611\n",
      "Train Epoch: 16 [5440/8640 (63%)]\tLoss: 0.094337\tLoss(dice): 0.073963\n",
      "Train Epoch: 16 [5760/8640 (67%)]\tLoss: 0.109039\tLoss(dice): 0.071748\n",
      "Train Epoch: 16 [6080/8640 (70%)]\tLoss: 0.106893\tLoss(dice): 0.074095\n",
      "Train Epoch: 16 [6400/8640 (74%)]\tLoss: 0.111240\tLoss(dice): 0.076323\n",
      "Train Epoch: 16 [6720/8640 (78%)]\tLoss: 0.096081\tLoss(dice): 0.075526\n",
      "Train Epoch: 16 [7040/8640 (81%)]\tLoss: 0.100149\tLoss(dice): 0.077351\n",
      "Train Epoch: 16 [7360/8640 (85%)]\tLoss: 0.101217\tLoss(dice): 0.078095\n",
      "Train Epoch: 16 [7680/8640 (89%)]\tLoss: 0.077066\tLoss(dice): 0.072046\n",
      "Train Epoch: 16 [8000/8640 (93%)]\tLoss: 0.107348\tLoss(dice): 0.076185\n",
      "Train Epoch: 16 [8320/8640 (96%)]\tLoss: 0.092142\tLoss(dice): 0.071763\n",
      "Validation\tLoss: 0.099432\tLoss(dice): 0.073545\n",
      "Train Epoch: 17 [0/8640 (0%)]\tLoss: 0.090006\tLoss(dice): 0.077387\n",
      "Train Epoch: 17 [320/8640 (4%)]\tLoss: 0.102664\tLoss(dice): 0.071192\n",
      "Train Epoch: 17 [640/8640 (7%)]\tLoss: 0.102699\tLoss(dice): 0.074627\n",
      "Train Epoch: 17 [960/8640 (11%)]\tLoss: 0.089133\tLoss(dice): 0.078361\n",
      "Train Epoch: 17 [1280/8640 (15%)]\tLoss: 0.079162\tLoss(dice): 0.074009\n",
      "Train Epoch: 17 [1600/8640 (19%)]\tLoss: 0.094997\tLoss(dice): 0.071339\n",
      "Train Epoch: 17 [1920/8640 (22%)]\tLoss: 0.113368\tLoss(dice): 0.072457\n",
      "Train Epoch: 17 [2240/8640 (26%)]\tLoss: 0.096592\tLoss(dice): 0.072835\n",
      "Train Epoch: 17 [2560/8640 (30%)]\tLoss: 0.091109\tLoss(dice): 0.071767\n",
      "Train Epoch: 17 [2880/8640 (33%)]\tLoss: 0.086534\tLoss(dice): 0.069331\n",
      "Train Epoch: 17 [3200/8640 (37%)]\tLoss: 0.096412\tLoss(dice): 0.069865\n",
      "Train Epoch: 17 [3520/8640 (41%)]\tLoss: 0.099498\tLoss(dice): 0.072833\n",
      "Train Epoch: 17 [3840/8640 (44%)]\tLoss: 0.100513\tLoss(dice): 0.073306\n",
      "Train Epoch: 17 [4160/8640 (48%)]\tLoss: 0.107310\tLoss(dice): 0.073090\n",
      "Train Epoch: 17 [4480/8640 (52%)]\tLoss: 0.088347\tLoss(dice): 0.074658\n",
      "Train Epoch: 17 [4800/8640 (56%)]\tLoss: 0.110747\tLoss(dice): 0.070687\n",
      "Train Epoch: 17 [5120/8640 (59%)]\tLoss: 0.088119\tLoss(dice): 0.073394\n",
      "Train Epoch: 17 [5440/8640 (63%)]\tLoss: 0.105105\tLoss(dice): 0.074858\n",
      "Train Epoch: 17 [5760/8640 (67%)]\tLoss: 0.089113\tLoss(dice): 0.077952\n",
      "Train Epoch: 17 [6080/8640 (70%)]\tLoss: 0.081165\tLoss(dice): 0.071843\n",
      "Train Epoch: 17 [6400/8640 (74%)]\tLoss: 0.111342\tLoss(dice): 0.069601\n",
      "Train Epoch: 17 [6720/8640 (78%)]\tLoss: 0.109486\tLoss(dice): 0.066428\n",
      "Train Epoch: 17 [7040/8640 (81%)]\tLoss: 0.086735\tLoss(dice): 0.072231\n",
      "Train Epoch: 17 [7360/8640 (85%)]\tLoss: 0.087826\tLoss(dice): 0.068351\n",
      "Train Epoch: 17 [7680/8640 (89%)]\tLoss: 0.098958\tLoss(dice): 0.065819\n",
      "Train Epoch: 17 [8000/8640 (93%)]\tLoss: 0.096706\tLoss(dice): 0.074602\n",
      "Train Epoch: 17 [8320/8640 (96%)]\tLoss: 0.097024\tLoss(dice): 0.072167\n",
      "Validation\tLoss: 0.097879\tLoss(dice): 0.072268\n",
      "Train Epoch: 18 [0/8640 (0%)]\tLoss: 0.079687\tLoss(dice): 0.070162\n",
      "Train Epoch: 18 [320/8640 (4%)]\tLoss: 0.076347\tLoss(dice): 0.072827\n",
      "Train Epoch: 18 [640/8640 (7%)]\tLoss: 0.100444\tLoss(dice): 0.074895\n",
      "Train Epoch: 18 [960/8640 (11%)]\tLoss: 0.091288\tLoss(dice): 0.071885\n",
      "Train Epoch: 18 [1280/8640 (15%)]\tLoss: 0.095434\tLoss(dice): 0.067208\n",
      "Train Epoch: 18 [1600/8640 (19%)]\tLoss: 0.086228\tLoss(dice): 0.072980\n",
      "Train Epoch: 18 [1920/8640 (22%)]\tLoss: 0.101285\tLoss(dice): 0.066605\n",
      "Train Epoch: 18 [2240/8640 (26%)]\tLoss: 0.101448\tLoss(dice): 0.068201\n",
      "Train Epoch: 18 [2560/8640 (30%)]\tLoss: 0.098699\tLoss(dice): 0.068045\n",
      "Train Epoch: 18 [2880/8640 (33%)]\tLoss: 0.090244\tLoss(dice): 0.072641\n",
      "Train Epoch: 18 [3200/8640 (37%)]\tLoss: 0.096846\tLoss(dice): 0.073318\n",
      "Train Epoch: 18 [3520/8640 (41%)]\tLoss: 0.109134\tLoss(dice): 0.072626\n",
      "Train Epoch: 18 [3840/8640 (44%)]\tLoss: 0.100838\tLoss(dice): 0.070067\n",
      "Train Epoch: 18 [4160/8640 (48%)]\tLoss: 0.096425\tLoss(dice): 0.075181\n",
      "Train Epoch: 18 [4480/8640 (52%)]\tLoss: 0.098073\tLoss(dice): 0.072308\n",
      "Train Epoch: 18 [4800/8640 (56%)]\tLoss: 0.097890\tLoss(dice): 0.077712\n",
      "Train Epoch: 18 [5120/8640 (59%)]\tLoss: 0.091121\tLoss(dice): 0.074806\n",
      "Train Epoch: 18 [5440/8640 (63%)]\tLoss: 0.102397\tLoss(dice): 0.070418\n",
      "Train Epoch: 18 [5760/8640 (67%)]\tLoss: 0.104085\tLoss(dice): 0.072124\n",
      "Train Epoch: 18 [6080/8640 (70%)]\tLoss: 0.097773\tLoss(dice): 0.069963\n",
      "Train Epoch: 18 [6400/8640 (74%)]\tLoss: 0.102338\tLoss(dice): 0.071367\n",
      "Train Epoch: 18 [6720/8640 (78%)]\tLoss: 0.104652\tLoss(dice): 0.067095\n",
      "Train Epoch: 18 [7040/8640 (81%)]\tLoss: 0.087956\tLoss(dice): 0.065484\n",
      "Train Epoch: 18 [7360/8640 (85%)]\tLoss: 0.084896\tLoss(dice): 0.071841\n",
      "Train Epoch: 18 [7680/8640 (89%)]\tLoss: 0.098381\tLoss(dice): 0.073166\n",
      "Train Epoch: 18 [8000/8640 (93%)]\tLoss: 0.086385\tLoss(dice): 0.069655\n",
      "Train Epoch: 18 [8320/8640 (96%)]\tLoss: 0.100827\tLoss(dice): 0.074978\n",
      "Validation\tLoss: 0.096632\tLoss(dice): 0.071104\n",
      "Train Epoch: 19 [0/8640 (0%)]\tLoss: 0.088663\tLoss(dice): 0.070283\n",
      "Train Epoch: 19 [320/8640 (4%)]\tLoss: 0.083557\tLoss(dice): 0.071971\n",
      "Train Epoch: 19 [640/8640 (7%)]\tLoss: 0.089572\tLoss(dice): 0.073071\n",
      "Train Epoch: 19 [960/8640 (11%)]\tLoss: 0.110732\tLoss(dice): 0.071247\n",
      "Train Epoch: 19 [1280/8640 (15%)]\tLoss: 0.089218\tLoss(dice): 0.073302\n",
      "Train Epoch: 19 [1600/8640 (19%)]\tLoss: 0.089281\tLoss(dice): 0.069514\n",
      "Train Epoch: 19 [1920/8640 (22%)]\tLoss: 0.082501\tLoss(dice): 0.074578\n",
      "Train Epoch: 19 [2240/8640 (26%)]\tLoss: 0.085267\tLoss(dice): 0.075205\n",
      "Train Epoch: 19 [2560/8640 (30%)]\tLoss: 0.093132\tLoss(dice): 0.071669\n",
      "Train Epoch: 19 [2880/8640 (33%)]\tLoss: 0.092991\tLoss(dice): 0.073140\n",
      "Train Epoch: 19 [3200/8640 (37%)]\tLoss: 0.095777\tLoss(dice): 0.065015\n",
      "Train Epoch: 19 [3520/8640 (41%)]\tLoss: 0.084191\tLoss(dice): 0.070992\n",
      "Train Epoch: 19 [3840/8640 (44%)]\tLoss: 0.087245\tLoss(dice): 0.072436\n",
      "Train Epoch: 19 [4160/8640 (48%)]\tLoss: 0.089916\tLoss(dice): 0.070559\n",
      "Train Epoch: 19 [4480/8640 (52%)]\tLoss: 0.100556\tLoss(dice): 0.072693\n",
      "Train Epoch: 19 [4800/8640 (56%)]\tLoss: 0.083663\tLoss(dice): 0.070243\n",
      "Train Epoch: 19 [5120/8640 (59%)]\tLoss: 0.097401\tLoss(dice): 0.067035\n",
      "Train Epoch: 19 [5440/8640 (63%)]\tLoss: 0.077549\tLoss(dice): 0.072817\n",
      "Train Epoch: 19 [5760/8640 (67%)]\tLoss: 0.092350\tLoss(dice): 0.071132\n",
      "Train Epoch: 19 [6080/8640 (70%)]\tLoss: 0.094631\tLoss(dice): 0.071932\n",
      "Train Epoch: 19 [6400/8640 (74%)]\tLoss: 0.095896\tLoss(dice): 0.069235\n",
      "Train Epoch: 19 [6720/8640 (78%)]\tLoss: 0.093542\tLoss(dice): 0.073484\n",
      "Train Epoch: 19 [7040/8640 (81%)]\tLoss: 0.107551\tLoss(dice): 0.072301\n",
      "Train Epoch: 19 [7360/8640 (85%)]\tLoss: 0.103942\tLoss(dice): 0.067471\n",
      "Train Epoch: 19 [7680/8640 (89%)]\tLoss: 0.094786\tLoss(dice): 0.070200\n",
      "Train Epoch: 19 [8000/8640 (93%)]\tLoss: 0.093522\tLoss(dice): 0.071540\n",
      "Train Epoch: 19 [8320/8640 (96%)]\tLoss: 0.097309\tLoss(dice): 0.074401\n",
      "Validation\tLoss: 0.095438\tLoss(dice): 0.070165\n",
      "Train Epoch: 20 [0/8640 (0%)]\tLoss: 0.111123\tLoss(dice): 0.072166\n",
      "Train Epoch: 20 [320/8640 (4%)]\tLoss: 0.081894\tLoss(dice): 0.071573\n",
      "Train Epoch: 20 [640/8640 (7%)]\tLoss: 0.090335\tLoss(dice): 0.073072\n",
      "Train Epoch: 20 [960/8640 (11%)]\tLoss: 0.093366\tLoss(dice): 0.066390\n",
      "Train Epoch: 20 [1280/8640 (15%)]\tLoss: 0.086456\tLoss(dice): 0.071842\n",
      "Train Epoch: 20 [1600/8640 (19%)]\tLoss: 0.091798\tLoss(dice): 0.069998\n",
      "Train Epoch: 20 [1920/8640 (22%)]\tLoss: 0.095267\tLoss(dice): 0.066278\n",
      "Train Epoch: 20 [2240/8640 (26%)]\tLoss: 0.098981\tLoss(dice): 0.065326\n",
      "Train Epoch: 20 [2560/8640 (30%)]\tLoss: 0.091415\tLoss(dice): 0.068052\n",
      "Train Epoch: 20 [2880/8640 (33%)]\tLoss: 0.083780\tLoss(dice): 0.073204\n",
      "Train Epoch: 20 [3200/8640 (37%)]\tLoss: 0.095536\tLoss(dice): 0.070891\n",
      "Train Epoch: 20 [3520/8640 (41%)]\tLoss: 0.100865\tLoss(dice): 0.069776\n",
      "Train Epoch: 20 [3840/8640 (44%)]\tLoss: 0.088421\tLoss(dice): 0.066894\n",
      "Train Epoch: 20 [4160/8640 (48%)]\tLoss: 0.098368\tLoss(dice): 0.065659\n",
      "Train Epoch: 20 [4480/8640 (52%)]\tLoss: 0.081466\tLoss(dice): 0.069452\n",
      "Train Epoch: 20 [4800/8640 (56%)]\tLoss: 0.093341\tLoss(dice): 0.068621\n",
      "Train Epoch: 20 [5120/8640 (59%)]\tLoss: 0.083810\tLoss(dice): 0.070350\n",
      "Train Epoch: 20 [5440/8640 (63%)]\tLoss: 0.089034\tLoss(dice): 0.071460\n",
      "Train Epoch: 20 [5760/8640 (67%)]\tLoss: 0.081134\tLoss(dice): 0.074452\n",
      "Train Epoch: 20 [6080/8640 (70%)]\tLoss: 0.086048\tLoss(dice): 0.071831\n",
      "Train Epoch: 20 [6400/8640 (74%)]\tLoss: 0.084775\tLoss(dice): 0.065742\n",
      "Train Epoch: 20 [6720/8640 (78%)]\tLoss: 0.097167\tLoss(dice): 0.068504\n",
      "Train Epoch: 20 [7040/8640 (81%)]\tLoss: 0.092902\tLoss(dice): 0.069962\n",
      "Train Epoch: 20 [7360/8640 (85%)]\tLoss: 0.104660\tLoss(dice): 0.069834\n",
      "Train Epoch: 20 [7680/8640 (89%)]\tLoss: 0.096246\tLoss(dice): 0.068185\n",
      "Train Epoch: 20 [8000/8640 (93%)]\tLoss: 0.092311\tLoss(dice): 0.067214\n",
      "Train Epoch: 20 [8320/8640 (96%)]\tLoss: 0.097122\tLoss(dice): 0.070493\n",
      "Validation\tLoss: 0.094465\tLoss(dice): 0.069291\n",
      "Train Epoch: 21 [0/8640 (0%)]\tLoss: 0.095164\tLoss(dice): 0.069087\n",
      "Train Epoch: 21 [320/8640 (4%)]\tLoss: 0.088356\tLoss(dice): 0.069754\n",
      "Train Epoch: 21 [640/8640 (7%)]\tLoss: 0.072296\tLoss(dice): 0.069094\n",
      "Train Epoch: 21 [960/8640 (11%)]\tLoss: 0.097000\tLoss(dice): 0.066898\n",
      "Train Epoch: 21 [1280/8640 (15%)]\tLoss: 0.078092\tLoss(dice): 0.072350\n",
      "Train Epoch: 21 [1600/8640 (19%)]\tLoss: 0.107932\tLoss(dice): 0.068243\n",
      "Train Epoch: 21 [1920/8640 (22%)]\tLoss: 0.102910\tLoss(dice): 0.070132\n",
      "Train Epoch: 21 [2240/8640 (26%)]\tLoss: 0.091369\tLoss(dice): 0.068532\n",
      "Train Epoch: 21 [2560/8640 (30%)]\tLoss: 0.110300\tLoss(dice): 0.064806\n",
      "Train Epoch: 21 [2880/8640 (33%)]\tLoss: 0.090691\tLoss(dice): 0.065881\n",
      "Train Epoch: 21 [3200/8640 (37%)]\tLoss: 0.108043\tLoss(dice): 0.068175\n",
      "Train Epoch: 21 [3520/8640 (41%)]\tLoss: 0.092335\tLoss(dice): 0.068453\n",
      "Train Epoch: 21 [3840/8640 (44%)]\tLoss: 0.081606\tLoss(dice): 0.069820\n",
      "Train Epoch: 21 [4160/8640 (48%)]\tLoss: 0.080706\tLoss(dice): 0.067808\n",
      "Train Epoch: 21 [4480/8640 (52%)]\tLoss: 0.091961\tLoss(dice): 0.069599\n",
      "Train Epoch: 21 [4800/8640 (56%)]\tLoss: 0.108591\tLoss(dice): 0.067230\n",
      "Train Epoch: 21 [5120/8640 (59%)]\tLoss: 0.092322\tLoss(dice): 0.069721\n",
      "Train Epoch: 21 [5440/8640 (63%)]\tLoss: 0.089085\tLoss(dice): 0.067365\n",
      "Train Epoch: 21 [5760/8640 (67%)]\tLoss: 0.087593\tLoss(dice): 0.064193\n",
      "Train Epoch: 21 [6080/8640 (70%)]\tLoss: 0.096903\tLoss(dice): 0.067068\n",
      "Train Epoch: 21 [6400/8640 (74%)]\tLoss: 0.080012\tLoss(dice): 0.073798\n",
      "Train Epoch: 21 [6720/8640 (78%)]\tLoss: 0.095755\tLoss(dice): 0.071726\n",
      "Train Epoch: 21 [7040/8640 (81%)]\tLoss: 0.088437\tLoss(dice): 0.066784\n",
      "Train Epoch: 21 [7360/8640 (85%)]\tLoss: 0.085444\tLoss(dice): 0.070429\n",
      "Train Epoch: 21 [7680/8640 (89%)]\tLoss: 0.096630\tLoss(dice): 0.068245\n",
      "Train Epoch: 21 [8000/8640 (93%)]\tLoss: 0.079838\tLoss(dice): 0.069108\n",
      "Train Epoch: 21 [8320/8640 (96%)]\tLoss: 0.088444\tLoss(dice): 0.066328\n",
      "Validation\tLoss: 0.093681\tLoss(dice): 0.068575\n",
      "Train Epoch: 22 [0/8640 (0%)]\tLoss: 0.089513\tLoss(dice): 0.067754\n",
      "Train Epoch: 22 [320/8640 (4%)]\tLoss: 0.070269\tLoss(dice): 0.073852\n",
      "Train Epoch: 22 [640/8640 (7%)]\tLoss: 0.082261\tLoss(dice): 0.068160\n",
      "Train Epoch: 22 [960/8640 (11%)]\tLoss: 0.089951\tLoss(dice): 0.070957\n",
      "Train Epoch: 22 [1280/8640 (15%)]\tLoss: 0.086757\tLoss(dice): 0.068107\n",
      "Train Epoch: 22 [1600/8640 (19%)]\tLoss: 0.103153\tLoss(dice): 0.069870\n",
      "Train Epoch: 22 [1920/8640 (22%)]\tLoss: 0.104753\tLoss(dice): 0.071123\n",
      "Train Epoch: 22 [2240/8640 (26%)]\tLoss: 0.082928\tLoss(dice): 0.068854\n",
      "Train Epoch: 22 [2560/8640 (30%)]\tLoss: 0.087680\tLoss(dice): 0.067506\n",
      "Train Epoch: 22 [2880/8640 (33%)]\tLoss: 0.085434\tLoss(dice): 0.070203\n",
      "Train Epoch: 22 [3200/8640 (37%)]\tLoss: 0.090788\tLoss(dice): 0.071308\n",
      "Train Epoch: 22 [3520/8640 (41%)]\tLoss: 0.096688\tLoss(dice): 0.071896\n",
      "Train Epoch: 22 [3840/8640 (44%)]\tLoss: 0.083968\tLoss(dice): 0.073878\n",
      "Train Epoch: 22 [4160/8640 (48%)]\tLoss: 0.102924\tLoss(dice): 0.068341\n",
      "Train Epoch: 22 [4480/8640 (52%)]\tLoss: 0.093799\tLoss(dice): 0.067655\n",
      "Train Epoch: 22 [4800/8640 (56%)]\tLoss: 0.094885\tLoss(dice): 0.069189\n",
      "Train Epoch: 22 [5120/8640 (59%)]\tLoss: 0.080447\tLoss(dice): 0.068970\n",
      "Train Epoch: 22 [5440/8640 (63%)]\tLoss: 0.093344\tLoss(dice): 0.072473\n",
      "Train Epoch: 22 [5760/8640 (67%)]\tLoss: 0.117570\tLoss(dice): 0.068355\n",
      "Train Epoch: 22 [6080/8640 (70%)]\tLoss: 0.099574\tLoss(dice): 0.064946\n",
      "Train Epoch: 22 [6400/8640 (74%)]\tLoss: 0.095053\tLoss(dice): 0.064898\n",
      "Train Epoch: 22 [6720/8640 (78%)]\tLoss: 0.094813\tLoss(dice): 0.066322\n",
      "Train Epoch: 22 [7040/8640 (81%)]\tLoss: 0.096977\tLoss(dice): 0.071932\n",
      "Train Epoch: 22 [7360/8640 (85%)]\tLoss: 0.081871\tLoss(dice): 0.066970\n",
      "Train Epoch: 22 [7680/8640 (89%)]\tLoss: 0.081147\tLoss(dice): 0.065473\n",
      "Train Epoch: 22 [8000/8640 (93%)]\tLoss: 0.092077\tLoss(dice): 0.066590\n",
      "Train Epoch: 22 [8320/8640 (96%)]\tLoss: 0.095427\tLoss(dice): 0.066657\n",
      "Validation\tLoss: 0.092865\tLoss(dice): 0.067937\n",
      "Train Epoch: 23 [0/8640 (0%)]\tLoss: 0.095665\tLoss(dice): 0.064664\n",
      "Train Epoch: 23 [320/8640 (4%)]\tLoss: 0.094495\tLoss(dice): 0.066198\n",
      "Train Epoch: 23 [640/8640 (7%)]\tLoss: 0.092250\tLoss(dice): 0.067954\n",
      "Train Epoch: 23 [960/8640 (11%)]\tLoss: 0.096428\tLoss(dice): 0.070542\n",
      "Train Epoch: 23 [1280/8640 (15%)]\tLoss: 0.084437\tLoss(dice): 0.072975\n",
      "Train Epoch: 23 [1600/8640 (19%)]\tLoss: 0.088785\tLoss(dice): 0.063829\n",
      "Train Epoch: 23 [1920/8640 (22%)]\tLoss: 0.092911\tLoss(dice): 0.068854\n",
      "Train Epoch: 23 [2240/8640 (26%)]\tLoss: 0.079922\tLoss(dice): 0.068690\n",
      "Train Epoch: 23 [2560/8640 (30%)]\tLoss: 0.083517\tLoss(dice): 0.070430\n",
      "Train Epoch: 23 [2880/8640 (33%)]\tLoss: 0.093030\tLoss(dice): 0.062148\n",
      "Train Epoch: 23 [3200/8640 (37%)]\tLoss: 0.101018\tLoss(dice): 0.065926\n",
      "Train Epoch: 23 [3520/8640 (41%)]\tLoss: 0.112587\tLoss(dice): 0.065442\n",
      "Train Epoch: 23 [3840/8640 (44%)]\tLoss: 0.100693\tLoss(dice): 0.067991\n",
      "Train Epoch: 23 [4160/8640 (48%)]\tLoss: 0.084217\tLoss(dice): 0.065364\n",
      "Train Epoch: 23 [4480/8640 (52%)]\tLoss: 0.097402\tLoss(dice): 0.064041\n",
      "Train Epoch: 23 [4800/8640 (56%)]\tLoss: 0.103133\tLoss(dice): 0.067800\n",
      "Train Epoch: 23 [5120/8640 (59%)]\tLoss: 0.083668\tLoss(dice): 0.065162\n",
      "Train Epoch: 23 [5440/8640 (63%)]\tLoss: 0.100874\tLoss(dice): 0.069442\n",
      "Train Epoch: 23 [5760/8640 (67%)]\tLoss: 0.091513\tLoss(dice): 0.066678\n",
      "Train Epoch: 23 [6080/8640 (70%)]\tLoss: 0.093486\tLoss(dice): 0.061810\n",
      "Train Epoch: 23 [6400/8640 (74%)]\tLoss: 0.095491\tLoss(dice): 0.070033\n",
      "Train Epoch: 23 [6720/8640 (78%)]\tLoss: 0.093762\tLoss(dice): 0.065479\n",
      "Train Epoch: 23 [7040/8640 (81%)]\tLoss: 0.084210\tLoss(dice): 0.069966\n",
      "Train Epoch: 23 [7360/8640 (85%)]\tLoss: 0.094491\tLoss(dice): 0.067992\n",
      "Train Epoch: 23 [7680/8640 (89%)]\tLoss: 0.098124\tLoss(dice): 0.067057\n",
      "Train Epoch: 23 [8000/8640 (93%)]\tLoss: 0.084548\tLoss(dice): 0.064461\n",
      "Train Epoch: 23 [8320/8640 (96%)]\tLoss: 0.099642\tLoss(dice): 0.064893\n",
      "Validation\tLoss: 0.092241\tLoss(dice): 0.067319\n",
      "Train Epoch: 24 [0/8640 (0%)]\tLoss: 0.098288\tLoss(dice): 0.066789\n",
      "Train Epoch: 24 [320/8640 (4%)]\tLoss: 0.081802\tLoss(dice): 0.071446\n",
      "Train Epoch: 24 [640/8640 (7%)]\tLoss: 0.092120\tLoss(dice): 0.070283\n",
      "Train Epoch: 24 [960/8640 (11%)]\tLoss: 0.080115\tLoss(dice): 0.073977\n",
      "Train Epoch: 24 [1280/8640 (15%)]\tLoss: 0.090705\tLoss(dice): 0.066804\n",
      "Train Epoch: 24 [1600/8640 (19%)]\tLoss: 0.104944\tLoss(dice): 0.065691\n",
      "Train Epoch: 24 [1920/8640 (22%)]\tLoss: 0.089612\tLoss(dice): 0.071731\n",
      "Train Epoch: 24 [2240/8640 (26%)]\tLoss: 0.097243\tLoss(dice): 0.062101\n",
      "Train Epoch: 24 [2560/8640 (30%)]\tLoss: 0.092794\tLoss(dice): 0.066585\n",
      "Train Epoch: 24 [2880/8640 (33%)]\tLoss: 0.084372\tLoss(dice): 0.068305\n",
      "Train Epoch: 24 [3200/8640 (37%)]\tLoss: 0.088940\tLoss(dice): 0.063972\n",
      "Train Epoch: 24 [3520/8640 (41%)]\tLoss: 0.099338\tLoss(dice): 0.068758\n",
      "Train Epoch: 24 [3840/8640 (44%)]\tLoss: 0.098636\tLoss(dice): 0.066132\n",
      "Train Epoch: 24 [4160/8640 (48%)]\tLoss: 0.086736\tLoss(dice): 0.071257\n",
      "Train Epoch: 24 [4480/8640 (52%)]\tLoss: 0.090327\tLoss(dice): 0.068117\n",
      "Train Epoch: 24 [4800/8640 (56%)]\tLoss: 0.092375\tLoss(dice): 0.069147\n",
      "Train Epoch: 24 [5120/8640 (59%)]\tLoss: 0.089724\tLoss(dice): 0.067416\n",
      "Train Epoch: 24 [5440/8640 (63%)]\tLoss: 0.090812\tLoss(dice): 0.063445\n",
      "Train Epoch: 24 [5760/8640 (67%)]\tLoss: 0.092226\tLoss(dice): 0.063820\n",
      "Train Epoch: 24 [6080/8640 (70%)]\tLoss: 0.086506\tLoss(dice): 0.067564\n",
      "Train Epoch: 24 [6400/8640 (74%)]\tLoss: 0.089188\tLoss(dice): 0.066213\n",
      "Train Epoch: 24 [6720/8640 (78%)]\tLoss: 0.086410\tLoss(dice): 0.073299\n",
      "Train Epoch: 24 [7040/8640 (81%)]\tLoss: 0.075915\tLoss(dice): 0.070555\n",
      "Train Epoch: 24 [7360/8640 (85%)]\tLoss: 0.080039\tLoss(dice): 0.070883\n",
      "Train Epoch: 24 [7680/8640 (89%)]\tLoss: 0.107837\tLoss(dice): 0.065669\n",
      "Train Epoch: 24 [8000/8640 (93%)]\tLoss: 0.087590\tLoss(dice): 0.065585\n",
      "Train Epoch: 24 [8320/8640 (96%)]\tLoss: 0.081641\tLoss(dice): 0.062444\n",
      "Validation\tLoss: 0.091561\tLoss(dice): 0.066795\n",
      "Train Epoch: 25 [0/8640 (0%)]\tLoss: 0.094951\tLoss(dice): 0.063925\n",
      "Train Epoch: 25 [320/8640 (4%)]\tLoss: 0.084323\tLoss(dice): 0.066207\n",
      "Train Epoch: 25 [640/8640 (7%)]\tLoss: 0.087143\tLoss(dice): 0.063667\n",
      "Train Epoch: 25 [960/8640 (11%)]\tLoss: 0.094691\tLoss(dice): 0.070017\n",
      "Train Epoch: 25 [1280/8640 (15%)]\tLoss: 0.078998\tLoss(dice): 0.064867\n",
      "Train Epoch: 25 [1600/8640 (19%)]\tLoss: 0.087914\tLoss(dice): 0.063277\n",
      "Train Epoch: 25 [1920/8640 (22%)]\tLoss: 0.089810\tLoss(dice): 0.066299\n",
      "Train Epoch: 25 [2240/8640 (26%)]\tLoss: 0.092819\tLoss(dice): 0.063406\n",
      "Train Epoch: 25 [2560/8640 (30%)]\tLoss: 0.089366\tLoss(dice): 0.071230\n",
      "Train Epoch: 25 [2880/8640 (33%)]\tLoss: 0.079969\tLoss(dice): 0.065752\n",
      "Train Epoch: 25 [3200/8640 (37%)]\tLoss: 0.087079\tLoss(dice): 0.073155\n",
      "Train Epoch: 25 [3520/8640 (41%)]\tLoss: 0.099218\tLoss(dice): 0.068609\n",
      "Train Epoch: 25 [3840/8640 (44%)]\tLoss: 0.100306\tLoss(dice): 0.067555\n",
      "Train Epoch: 25 [4160/8640 (48%)]\tLoss: 0.091494\tLoss(dice): 0.064830\n",
      "Train Epoch: 25 [4480/8640 (52%)]\tLoss: 0.085626\tLoss(dice): 0.067847\n",
      "Train Epoch: 25 [4800/8640 (56%)]\tLoss: 0.082435\tLoss(dice): 0.066010\n",
      "Train Epoch: 25 [5120/8640 (59%)]\tLoss: 0.096174\tLoss(dice): 0.068433\n",
      "Train Epoch: 25 [5440/8640 (63%)]\tLoss: 0.087104\tLoss(dice): 0.060421\n",
      "Train Epoch: 25 [5760/8640 (67%)]\tLoss: 0.092643\tLoss(dice): 0.068615\n",
      "Train Epoch: 25 [6080/8640 (70%)]\tLoss: 0.103680\tLoss(dice): 0.068950\n",
      "Train Epoch: 25 [6400/8640 (74%)]\tLoss: 0.090887\tLoss(dice): 0.068030\n",
      "Train Epoch: 25 [6720/8640 (78%)]\tLoss: 0.094892\tLoss(dice): 0.065499\n",
      "Train Epoch: 25 [7040/8640 (81%)]\tLoss: 0.083443\tLoss(dice): 0.071568\n",
      "Train Epoch: 25 [7360/8640 (85%)]\tLoss: 0.095466\tLoss(dice): 0.065271\n",
      "Train Epoch: 25 [7680/8640 (89%)]\tLoss: 0.108685\tLoss(dice): 0.068347\n",
      "Train Epoch: 25 [8000/8640 (93%)]\tLoss: 0.088704\tLoss(dice): 0.060468\n",
      "Train Epoch: 25 [8320/8640 (96%)]\tLoss: 0.095431\tLoss(dice): 0.072452\n",
      "Validation\tLoss: 0.091005\tLoss(dice): 0.066296\n",
      "Train Epoch: 26 [0/8640 (0%)]\tLoss: 0.091884\tLoss(dice): 0.067670\n",
      "Train Epoch: 26 [320/8640 (4%)]\tLoss: 0.103448\tLoss(dice): 0.069542\n",
      "Train Epoch: 26 [640/8640 (7%)]\tLoss: 0.102645\tLoss(dice): 0.064860\n",
      "Train Epoch: 26 [960/8640 (11%)]\tLoss: 0.083944\tLoss(dice): 0.067901\n",
      "Train Epoch: 26 [1280/8640 (15%)]\tLoss: 0.101925\tLoss(dice): 0.064920\n",
      "Train Epoch: 26 [1600/8640 (19%)]\tLoss: 0.098928\tLoss(dice): 0.064758\n",
      "Train Epoch: 26 [1920/8640 (22%)]\tLoss: 0.086351\tLoss(dice): 0.063129\n",
      "Train Epoch: 26 [2240/8640 (26%)]\tLoss: 0.105497\tLoss(dice): 0.061506\n",
      "Train Epoch: 26 [2560/8640 (30%)]\tLoss: 0.078415\tLoss(dice): 0.068157\n",
      "Train Epoch: 26 [2880/8640 (33%)]\tLoss: 0.088180\tLoss(dice): 0.068232\n",
      "Train Epoch: 26 [3200/8640 (37%)]\tLoss: 0.101590\tLoss(dice): 0.061483\n",
      "Train Epoch: 26 [3520/8640 (41%)]\tLoss: 0.099519\tLoss(dice): 0.067523\n",
      "Train Epoch: 26 [3840/8640 (44%)]\tLoss: 0.076264\tLoss(dice): 0.065007\n",
      "Train Epoch: 26 [4160/8640 (48%)]\tLoss: 0.082897\tLoss(dice): 0.067333\n",
      "Train Epoch: 26 [4480/8640 (52%)]\tLoss: 0.080166\tLoss(dice): 0.065428\n",
      "Train Epoch: 26 [4800/8640 (56%)]\tLoss: 0.080956\tLoss(dice): 0.064120\n",
      "Train Epoch: 26 [5120/8640 (59%)]\tLoss: 0.082015\tLoss(dice): 0.061106\n",
      "Train Epoch: 26 [5440/8640 (63%)]\tLoss: 0.075738\tLoss(dice): 0.069525\n",
      "Train Epoch: 26 [5760/8640 (67%)]\tLoss: 0.082916\tLoss(dice): 0.061978\n",
      "Train Epoch: 26 [6080/8640 (70%)]\tLoss: 0.084216\tLoss(dice): 0.065615\n",
      "Train Epoch: 26 [6400/8640 (74%)]\tLoss: 0.087136\tLoss(dice): 0.064536\n",
      "Train Epoch: 26 [6720/8640 (78%)]\tLoss: 0.094110\tLoss(dice): 0.063256\n",
      "Train Epoch: 26 [7040/8640 (81%)]\tLoss: 0.101438\tLoss(dice): 0.060989\n",
      "Train Epoch: 26 [7360/8640 (85%)]\tLoss: 0.090267\tLoss(dice): 0.062608\n",
      "Train Epoch: 26 [7680/8640 (89%)]\tLoss: 0.100369\tLoss(dice): 0.065256\n",
      "Train Epoch: 26 [8000/8640 (93%)]\tLoss: 0.097976\tLoss(dice): 0.069043\n",
      "Train Epoch: 26 [8320/8640 (96%)]\tLoss: 0.086771\tLoss(dice): 0.064966\n",
      "Validation\tLoss: 0.090496\tLoss(dice): 0.065814\n",
      "Train Epoch: 27 [0/8640 (0%)]\tLoss: 0.104857\tLoss(dice): 0.065319\n",
      "Train Epoch: 27 [320/8640 (4%)]\tLoss: 0.088170\tLoss(dice): 0.069041\n",
      "Train Epoch: 27 [640/8640 (7%)]\tLoss: 0.082733\tLoss(dice): 0.066935\n",
      "Train Epoch: 27 [960/8640 (11%)]\tLoss: 0.087427\tLoss(dice): 0.062195\n",
      "Train Epoch: 27 [1280/8640 (15%)]\tLoss: 0.081011\tLoss(dice): 0.070772\n",
      "Train Epoch: 27 [1600/8640 (19%)]\tLoss: 0.081648\tLoss(dice): 0.066709\n",
      "Train Epoch: 27 [1920/8640 (22%)]\tLoss: 0.082320\tLoss(dice): 0.063427\n",
      "Train Epoch: 27 [2240/8640 (26%)]\tLoss: 0.080317\tLoss(dice): 0.064661\n",
      "Train Epoch: 27 [2560/8640 (30%)]\tLoss: 0.091985\tLoss(dice): 0.065814\n",
      "Train Epoch: 27 [2880/8640 (33%)]\tLoss: 0.074647\tLoss(dice): 0.069106\n",
      "Train Epoch: 27 [3200/8640 (37%)]\tLoss: 0.102932\tLoss(dice): 0.067870\n",
      "Train Epoch: 27 [3520/8640 (41%)]\tLoss: 0.080967\tLoss(dice): 0.064284\n",
      "Train Epoch: 27 [3840/8640 (44%)]\tLoss: 0.087346\tLoss(dice): 0.063630\n",
      "Train Epoch: 27 [4160/8640 (48%)]\tLoss: 0.077535\tLoss(dice): 0.062547\n",
      "Train Epoch: 27 [4480/8640 (52%)]\tLoss: 0.090225\tLoss(dice): 0.068873\n",
      "Train Epoch: 27 [4800/8640 (56%)]\tLoss: 0.086981\tLoss(dice): 0.059496\n",
      "Train Epoch: 27 [5120/8640 (59%)]\tLoss: 0.079479\tLoss(dice): 0.067094\n",
      "Train Epoch: 27 [5440/8640 (63%)]\tLoss: 0.088396\tLoss(dice): 0.065297\n",
      "Train Epoch: 27 [5760/8640 (67%)]\tLoss: 0.084823\tLoss(dice): 0.066242\n",
      "Train Epoch: 27 [6080/8640 (70%)]\tLoss: 0.083253\tLoss(dice): 0.065819\n",
      "Train Epoch: 27 [6400/8640 (74%)]\tLoss: 0.099920\tLoss(dice): 0.067368\n",
      "Train Epoch: 27 [6720/8640 (78%)]\tLoss: 0.093109\tLoss(dice): 0.064722\n",
      "Train Epoch: 27 [7040/8640 (81%)]\tLoss: 0.091201\tLoss(dice): 0.067751\n",
      "Train Epoch: 27 [7360/8640 (85%)]\tLoss: 0.079067\tLoss(dice): 0.061923\n",
      "Train Epoch: 27 [7680/8640 (89%)]\tLoss: 0.098431\tLoss(dice): 0.063441\n",
      "Train Epoch: 27 [8000/8640 (93%)]\tLoss: 0.078028\tLoss(dice): 0.064022\n",
      "Train Epoch: 27 [8320/8640 (96%)]\tLoss: 0.087239\tLoss(dice): 0.065062\n",
      "Validation\tLoss: 0.089946\tLoss(dice): 0.065325\n",
      "Train Epoch: 28 [0/8640 (0%)]\tLoss: 0.089451\tLoss(dice): 0.065321\n",
      "Train Epoch: 28 [320/8640 (4%)]\tLoss: 0.084942\tLoss(dice): 0.067660\n",
      "Train Epoch: 28 [640/8640 (7%)]\tLoss: 0.095949\tLoss(dice): 0.066055\n",
      "Train Epoch: 28 [960/8640 (11%)]\tLoss: 0.097210\tLoss(dice): 0.065921\n",
      "Train Epoch: 28 [1280/8640 (15%)]\tLoss: 0.095391\tLoss(dice): 0.064464\n",
      "Train Epoch: 28 [1600/8640 (19%)]\tLoss: 0.098309\tLoss(dice): 0.063716\n",
      "Train Epoch: 28 [1920/8640 (22%)]\tLoss: 0.098486\tLoss(dice): 0.064317\n",
      "Train Epoch: 28 [2240/8640 (26%)]\tLoss: 0.080832\tLoss(dice): 0.068066\n",
      "Train Epoch: 28 [2560/8640 (30%)]\tLoss: 0.078803\tLoss(dice): 0.063946\n",
      "Train Epoch: 28 [2880/8640 (33%)]\tLoss: 0.094203\tLoss(dice): 0.065771\n",
      "Train Epoch: 28 [3200/8640 (37%)]\tLoss: 0.081027\tLoss(dice): 0.067151\n",
      "Train Epoch: 28 [3520/8640 (41%)]\tLoss: 0.096574\tLoss(dice): 0.065863\n",
      "Train Epoch: 28 [3840/8640 (44%)]\tLoss: 0.097177\tLoss(dice): 0.063886\n",
      "Train Epoch: 28 [4160/8640 (48%)]\tLoss: 0.100392\tLoss(dice): 0.064015\n",
      "Train Epoch: 28 [4480/8640 (52%)]\tLoss: 0.097176\tLoss(dice): 0.069482\n",
      "Train Epoch: 28 [4800/8640 (56%)]\tLoss: 0.085041\tLoss(dice): 0.070030\n",
      "Train Epoch: 28 [5120/8640 (59%)]\tLoss: 0.102312\tLoss(dice): 0.064275\n",
      "Train Epoch: 28 [5440/8640 (63%)]\tLoss: 0.109412\tLoss(dice): 0.061927\n",
      "Train Epoch: 28 [5760/8640 (67%)]\tLoss: 0.077860\tLoss(dice): 0.067099\n",
      "Train Epoch: 28 [6080/8640 (70%)]\tLoss: 0.099156\tLoss(dice): 0.059964\n",
      "Train Epoch: 28 [6400/8640 (74%)]\tLoss: 0.070467\tLoss(dice): 0.064504\n",
      "Train Epoch: 28 [6720/8640 (78%)]\tLoss: 0.086087\tLoss(dice): 0.063000\n",
      "Train Epoch: 28 [7040/8640 (81%)]\tLoss: 0.085326\tLoss(dice): 0.065357\n",
      "Train Epoch: 28 [7360/8640 (85%)]\tLoss: 0.098592\tLoss(dice): 0.066139\n",
      "Train Epoch: 28 [7680/8640 (89%)]\tLoss: 0.070709\tLoss(dice): 0.063070\n",
      "Train Epoch: 28 [8000/8640 (93%)]\tLoss: 0.070980\tLoss(dice): 0.065062\n",
      "Train Epoch: 28 [8320/8640 (96%)]\tLoss: 0.088223\tLoss(dice): 0.064859\n",
      "Validation\tLoss: 0.089371\tLoss(dice): 0.064938\n",
      "Train Epoch: 29 [0/8640 (0%)]\tLoss: 0.095621\tLoss(dice): 0.059868\n",
      "Train Epoch: 29 [320/8640 (4%)]\tLoss: 0.079379\tLoss(dice): 0.065050\n",
      "Train Epoch: 29 [640/8640 (7%)]\tLoss: 0.077859\tLoss(dice): 0.066247\n",
      "Train Epoch: 29 [960/8640 (11%)]\tLoss: 0.084461\tLoss(dice): 0.065699\n",
      "Train Epoch: 29 [1280/8640 (15%)]\tLoss: 0.105375\tLoss(dice): 0.067753\n",
      "Train Epoch: 29 [1600/8640 (19%)]\tLoss: 0.083011\tLoss(dice): 0.067378\n",
      "Train Epoch: 29 [1920/8640 (22%)]\tLoss: 0.078818\tLoss(dice): 0.065875\n",
      "Train Epoch: 29 [2240/8640 (26%)]\tLoss: 0.089151\tLoss(dice): 0.061113\n",
      "Train Epoch: 29 [2560/8640 (30%)]\tLoss: 0.091695\tLoss(dice): 0.065861\n",
      "Train Epoch: 29 [2880/8640 (33%)]\tLoss: 0.082143\tLoss(dice): 0.063489\n",
      "Train Epoch: 29 [3200/8640 (37%)]\tLoss: 0.077157\tLoss(dice): 0.069542\n",
      "Train Epoch: 29 [3520/8640 (41%)]\tLoss: 0.089983\tLoss(dice): 0.063412\n",
      "Train Epoch: 29 [3840/8640 (44%)]\tLoss: 0.084969\tLoss(dice): 0.060857\n",
      "Train Epoch: 29 [4160/8640 (48%)]\tLoss: 0.097124\tLoss(dice): 0.067029\n",
      "Train Epoch: 29 [4480/8640 (52%)]\tLoss: 0.088886\tLoss(dice): 0.067579\n",
      "Train Epoch: 29 [4800/8640 (56%)]\tLoss: 0.076210\tLoss(dice): 0.063722\n",
      "Train Epoch: 29 [5120/8640 (59%)]\tLoss: 0.091171\tLoss(dice): 0.064123\n",
      "Train Epoch: 29 [5440/8640 (63%)]\tLoss: 0.094698\tLoss(dice): 0.060053\n",
      "Train Epoch: 29 [5760/8640 (67%)]\tLoss: 0.073685\tLoss(dice): 0.065715\n",
      "Train Epoch: 29 [6080/8640 (70%)]\tLoss: 0.082795\tLoss(dice): 0.063390\n",
      "Train Epoch: 29 [6400/8640 (74%)]\tLoss: 0.095261\tLoss(dice): 0.063276\n",
      "Train Epoch: 29 [6720/8640 (78%)]\tLoss: 0.098823\tLoss(dice): 0.060611\n",
      "Train Epoch: 29 [7040/8640 (81%)]\tLoss: 0.095161\tLoss(dice): 0.062817\n",
      "Train Epoch: 29 [7360/8640 (85%)]\tLoss: 0.099185\tLoss(dice): 0.063502\n",
      "Train Epoch: 29 [7680/8640 (89%)]\tLoss: 0.069503\tLoss(dice): 0.063624\n",
      "Train Epoch: 29 [8000/8640 (93%)]\tLoss: 0.092022\tLoss(dice): 0.063751\n",
      "Train Epoch: 29 [8320/8640 (96%)]\tLoss: 0.079629\tLoss(dice): 0.069050\n",
      "Validation\tLoss: 0.088836\tLoss(dice): 0.064423\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "train_losses, val_losses = [], []\n",
    "epochs = 30\n",
    "for epoch in range(1, epochs):\n",
    "    train(epoch)\n",
    "    validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f65649d5ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_losses = np.array(train_losses)\n",
    "val_losses = np.array(val_losses)\n",
    "\n",
    "val_indices = np.linspace(0, (epochs-1)*len(train_loader)/print_steps, epochs-1)\n",
    "\n",
    "plt.plot(train_losses, '-', label='train loss')\n",
    "plt.plot(val_indices, val_losses, '--', label='val loss')\n",
    "plt.yscale(\"log\", nonposy='clip')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('BCELoss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_data, val_target = get_random_sample(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_pred = model(val_data)\n",
    "val_pred_arr = val_pred.data.cpu().squeeze_().numpy()\n",
    "val_target_arr = val_target.data.cpu().squeeze_().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,u'Absolute error')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f655f79fcd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3)\n",
    "ax1.imshow(val_pred_arr)\n",
    "ax1.set_title('Prediction')\n",
    "ax2.imshow(val_target_arr)\n",
    "ax2.set_title('Target')\n",
    "ax3.imshow(np.abs(val_pred_arr - val_target_arr))\n",
    "ax3.set_title('Absolute error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
